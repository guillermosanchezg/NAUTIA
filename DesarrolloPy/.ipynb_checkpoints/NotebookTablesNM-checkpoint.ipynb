{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 21 12:34:54 2020\n",
    "\n",
    "@author: guill\n",
    "\"\"\"\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "#pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "#import nltk\n",
    "#nltk.download(\"popular\") # required to download the stopwords lists\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "#spanish_stopwords = stopwords.words('spanish')\n",
    "#english_stopwords = stopwords.words('english')\n",
    "\n",
    "originalpath = \"C:/Users/guill/Documents/Universidad/PlataformaRefugiados/NAUTIA/DesarrolloPy/DataSetOriginales\"\n",
    "finalpath = \"C:/Users/guill/Documents/Universidad/PlataformaRefugiados/NAUTIA/DesarrolloPy/DataSetFinales\"\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  port = 3309,\n",
    "  host=\"127.0.0.1\",\n",
    "  user=\"root\",\n",
    "  passwd=\"\",\n",
    "  database = 'nautiatoolkit'\n",
    ")\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "def is_non_zero_file(fpath):\n",
    "    return os.path.isfile(fpath) and os.path.getsize(fpath)\n",
    "\n",
    "def getTableName(elem):\n",
    "    if(elem.find(\"_has_camp\") != -1):\n",
    "        x = elem.replace(\"_has_camp\",\"\")\n",
    "    else:\n",
    "        if(elem.find(\"_has_country\") != -1):\n",
    "            x = elem.replace(\"_has_country\",\"\")\n",
    "        else:\n",
    "            if(elem.find(\"_has_community\") != -1):\n",
    "                x = elem.replace(\"_has_community\",\"\")\n",
    "    return x\n",
    "\n",
    "#AQUIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "\n",
    "def get_communityFK(elem):\n",
    "    if(elem.find(\"_has_camp\") != -1):\n",
    "        cursor.execute(\"SELECT idCamp FROM camp ORDER BY idCamp DESC LIMIT 1\")\n",
    "    else:\n",
    "        if(elem.find(\"_has_country\") != -1):\n",
    "            cursor.execute(\"SELECT idCountry FROM Country ORDER BY idCountry DESC LIMIT 1\")\n",
    "        else:\n",
    "            if(elem.find(\"_has_community\") != -1):\n",
    "                cursor.execute(\"SELECT idCommunity FROM community ORDER BY idCommunity DESC LIMIT 1\")\n",
    "    return cursor.fetchall()\n",
    "\n",
    "def get_tableFK(df,index):\n",
    "    array = np.array(df)\n",
    "    return array[index][0]\n",
    "\n",
    "\n",
    "def fixBibliography(df):\n",
    "    df = dfFix(df,\"GENERAL INFORMATION - COUNTRY LEVEL\")\n",
    "    df.columns = ['GeneralInfo', 'CommunityCountry', 'RefugeeCountry']\n",
    "    df.set_index('GeneralInfo', inplace = True)\n",
    "    df = df.transpose()\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def dfFix(df,col1 = False,col2 = False):\n",
    "    result = df.copy()\n",
    "    if(col1):\n",
    "        x = result.columns.get_loc(col1)\n",
    "        result.drop(result.columns[0:x],axis = 1, inplace = True)\n",
    "    if(col2):\n",
    "        y = result.columns.get_loc(col2)\n",
    "        result.drop(result.columns[y:],axis = 1, inplace = True)\n",
    "    return result\n",
    "\n",
    "def validColumn(cad):\n",
    "    result = False\n",
    "    if(cad == \"index\"):#Population\n",
    "        result = True\n",
    "    else:\n",
    "        if(cad == \"Type_of_settlement\"):\n",
    "            result = True\n",
    "        else:\n",
    "            if(cad == \"General:settlement\"):\n",
    "                result = True\n",
    "            else:\n",
    "                if(cad == \"general_info:_1_1_Choose_the_settlement\"):\n",
    "                    result = True\n",
    "                else:\n",
    "                    if(cad == \"General_Information:Type_of_setlement\"):\n",
    "                        result = True\n",
    "                    else:\n",
    "                        if(cad == \"General:Settlement\"):\n",
    "                            result = True\n",
    "                        else:\n",
    "                            if(cad == \"Type_of_setlement\"):\n",
    "                                result = True\n",
    "    return result\n",
    "\n",
    "def dropRow(df,i):\n",
    "    return df.drop(index = i)\n",
    "\n",
    "def get_communityRows(df,cad,communityType): #la funci√≥n pd.loc[] tiene un bug indiscriminado (https://github.com/pandas-dev/pandas/issues/8555)\n",
    "    result = df\n",
    "    if(communityType == 0):\n",
    "        comm = \"host_community\"\n",
    "    else:\n",
    "        comm = \"refugee_camp\"\n",
    "    for index, row in df.iterrows():\n",
    "        if(row[cad] != comm):\n",
    "            result = dropRow(result,index)\n",
    "    return result\n",
    "\n",
    "def setDataByIndex(df,communityType):\n",
    "    array = df.columns\n",
    "    i = 0\n",
    "    df = df.replace(\"refugee\",\"refugee_camp\")\n",
    "    df = df.replace(\"host_comunity\",\"host_community\")\n",
    "    df = df.replace(\"RefugeeCountry\",\"refugee_camp\")\n",
    "    df = df.replace(\"CommunityCountry\",\"host_community\")\n",
    "    while(validColumn(array[i]) == False):\n",
    "        i += 1\n",
    "    df = get_communityRows(df,array[i],communityType)\n",
    "    return df\n",
    "\n",
    "def set_AllCSVtoDF(communityType):\n",
    "    Bibliography = pd.read_excel(getPath(originalpath,\"Bibliography_120220.xlsx\"))\n",
    "    Bibliography = fixBibliography(Bibliography)\n",
    "    Bibliography = setDataByIndex(Bibliography,communityType)\n",
    "    Entities = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Entities_Interview_results.csv\")),communityType)\n",
    "    LocalLeaders = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Local_leaders_v3_results.csv\")),communityType)\n",
    "    HouseHold = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Survey_household_v6_results.csv\")),communityType)\n",
    "    WomenGroup = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Women_Focus_Group2_results.csv\")),communityType)\n",
    "    SanitationInfra = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_V1_0_Sanitation_Infrastructre_results.csv\")),communityType)\n",
    "    Priorities = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Priorities_v3_results.csv\")),communityType)\n",
    "    GeneralForm = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_General_form_v3_results.csv\")),communityType)\n",
    "    PublicSpace = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Public_Space_results.csv\")),communityType)\n",
    "    WaterInf = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Water_Infrastructure_results.csv\")),communityType)\n",
    "    SanitationInf = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_V1_0_Sanitation_Infrastructre_results.csv\")),communityType)\n",
    "    WasteManagementInf = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Waste_Management_Infrastructure_results.csv\")),communityType)\n",
    "    EnergyINF = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Energy_Infrastructure_results.csv\")),communityType)\n",
    "    Business = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA1_0_Business_surveys_v3_results.csv\")),communityType)\n",
    "    MobilityINF = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0__Transport_servicesaccess_points_results.csv\")),communityType) \n",
    "    ComunalServices = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Communal_Services_results.csv\")),communityType) \n",
    "    GeneralCitizen = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_General_Citizen_Focus_Group_results.csv\")),communityType)\n",
    "    Shelter = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Shelter_results.csv\")),communityType)\n",
    "    FarmyardCrop = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Farmyard_and_Crops_results.csv\")),communityType)\n",
    "    return Bibliography,Entities,LocalLeaders,HouseHold,WomenGroup,SanitationInfra,Priorities,GeneralForm,PublicSpace,WaterInf,EnergyINF,SanitationInf,WasteManagementInf,EnergyINF,Business,MobilityINF,ComunalServices,GeneralCitizen,Shelter,FarmyardCrop\n",
    "\n",
    "def concatDF(df1,df2):\n",
    "    return  pd.concat([df1,df2],axis = 1, ignore_index = True, sort = True)\n",
    "\n",
    "def mkCSV(df,fileName):\n",
    "    df = df.dropna(how = 'all')\n",
    "    df *= 1   \n",
    "    fileName = fileName.lower()\n",
    "    df.to_csv('DataSetFinales/'+fileName,sep=',',header = False, index=False, encoding='utf-8')\n",
    "    \n",
    "def getPath(mainpath,filename):\n",
    "    return os.path.join(mainpath, filename)\n",
    "\n",
    "def getSubColumnNames(df,x):\n",
    "    columns = df.columns\n",
    "    array = []\n",
    "    for column in columns:\n",
    "        column = column[x:]\n",
    "        array.append(column)\n",
    "    return pd.DataFrame(array) \n",
    "\n",
    "def addInstitutionAndType(df,array1,array2,instType):\n",
    "    df = df.dropna(axis = 1)\n",
    "    df = np.array(df)\n",
    "    for row in df:\n",
    "        for elem in row:\n",
    "            array1 = np.append(array1,elem)\n",
    "            array2 = np.append(array2,instType)\n",
    "    return array1,array2\n",
    "\n",
    "def politicalActor(df1,df2,df3,df4,df5):\n",
    "    institution = []\n",
    "    instType = []\n",
    "\n",
    "    institution, instType  = addInstitutionAndType(df1,institution,instType,'Public Institution')\n",
    "    institution, instType  = addInstitutionAndType(df2,institution,instType,'Private Institution')\n",
    "    institution, instType  = addInstitutionAndType(df3,institution,instType,'NGO')\n",
    "    institution, instType  = addInstitutionAndType(df4,institution,instType,'International Agency')\n",
    "    institution, instType  = addInstitutionAndType(df5,institution,instType,'Local')\n",
    "\n",
    "    institution = pd.DataFrame(institution)\n",
    "    institution = institution.reset_index(drop = True)\n",
    "    instType = pd.DataFrame(instType)\n",
    "    instType = instType.reset_index(drop = True)\n",
    "    \n",
    "    return concatDF(institution,instType)\n",
    "\n",
    "\n",
    "def get_claveValor(df1,df2):\n",
    "    array1 = np.array(df2)\n",
    "    array2 = np.array(df1)\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    i = 0\n",
    "    for row in array1:\n",
    "        var = array2[i]\n",
    "        for elem in row:\n",
    "            result1 = np.append(result1,elem)\n",
    "            result2 = np.append(result2,var)\n",
    "        i+=1\n",
    "    result2 = pd.DataFrame(result2)\n",
    "    result2 = result2.reset_index(drop = True)\n",
    "    result1 = pd.DataFrame(result1)\n",
    "    result1 = result1.reset_index(drop = True)\n",
    "    return concatDF(result2,result1)\n",
    "\n",
    "def get_number(df):\n",
    "    df = np.array(df)\n",
    "    array = np.array([])\n",
    "    for column in df:\n",
    "        for elem in column:\n",
    "            array = np.append(array,elem)\n",
    "    return (pd.DataFrame(array)).fillna(0) \n",
    "\n",
    "def get_valueBySector(df1,df2):\n",
    "    df2 = df2.reset_index()\n",
    "    array1 = np.array(df1)\n",
    "    i = 0\n",
    "    for row in array1:\n",
    "        for elem in row:\n",
    "            if(elem == False):\n",
    "                df2 = dropRow(df2,i)\n",
    "        i += 1\n",
    "    df2 = df2.set_index('index')\n",
    "    return df2\n",
    "\n",
    "\n",
    "def separateValues(df):\n",
    "    if(df.isnull().values.all(axis=0)):\n",
    "        result = df\n",
    "    else:\n",
    "        array = np.array(df)\n",
    "        count_vectorizer = CountVectorizer(stop_words = spanish_stopwords+english_stopwords)\n",
    "        corpus = []\n",
    "        for row in array:\n",
    "            for elem in row:\n",
    "                corpus = np.append(corpus,[elem])\n",
    "        X = count_vectorizer.fit_transform(corpus)\n",
    "        array = count_vectorizer.get_feature_names()\n",
    "        result = pd.DataFrame(array)\n",
    "    return result\n",
    "\n",
    "def vectorizeValue(df):\n",
    "    df = separateValues(df)\n",
    "    year = np.array(['january','february','march','april','may','june','july','august','september','october','november','december'])\n",
    "    result = np.array([],dtype = bool)\n",
    "    df = np.array(df)\n",
    "    for elem in year:\n",
    "        flag = False\n",
    "        for column in df:\n",
    "            for month in column:\n",
    "                if(column == elem):\n",
    "                    flag = True\n",
    "        if(flag):\n",
    "            result = np.append(result,True)\n",
    "        else:\n",
    "            result = np.append(result,False)\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "def set_sector(df,sect, concat = True):\n",
    "    sector = np.array([])\n",
    "    df = df.dropna(how = 'all')\n",
    "    df = np.array(df)\n",
    "    for column in df:\n",
    "        sector = np.append(sector,sect)\n",
    "    sector = pd.DataFrame(sector)\n",
    "    df = pd.DataFrame(df)\n",
    "    if(concat):\n",
    "        result = concatDF(sector,df)\n",
    "    else:\n",
    "        result = sector\n",
    "    return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def selectAll(table,community):\n",
    "    cursor.execute(\"SELECT * FROM \"+table)\n",
    "    df1 = pd.DataFrame(cursor.fetchall())\n",
    "    cols=list(df1.columns)\n",
    "    for col in cols:\n",
    "        df1[col] = df1[col].astype(str).str.replace(\"\\r\",\"\")\n",
    "    df2 = pd.read_csv(getPath(finalpath,table+\".csv\"))\n",
    "    print(df1)\n",
    "    print(df2)\n",
    "    if(community.find(\"_has_camp\") != -1):\n",
    "        cursor.execute(\"SELECT * FROM \"+table+\" WHERE id\"+table+\"= (SELECT idCamp FROM camp ORDER BY idCamp DESC LIMIT 1)\")\n",
    "    else:\n",
    "        if(community.find(\"_has_country\") != -1):\n",
    "            cursor.execute(\"SELECT idCountry FROM Country ORDER BY idCountry DESC LIMIT 1\")\n",
    "        else:\n",
    "            if(community.find(\"_has_community\") != -1):\n",
    "                cursor.execute(\"SELECT idCommunity FROM community ORDER BY idCommunity DESC LIMIT 1\")\n",
    "    return cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0          1\n",
      "0  1  comercial\n",
      "1  2  comercial\n",
      "   comercial\n",
      "0  comercial\n",
      "   0     1\n",
      "0  1   nan\n",
      "1  2   one\n",
      "2  3  teff\n",
      "    nan\n",
      "0   one\n",
      "1  teff\n",
      "   0            1\n",
      "0  1        coral\n",
      "1  2  dactylifera\n",
      "2  3          nan\n",
      "3  4      phoenix\n",
      "4  5        √°rbol\n",
      "         coral\n",
      "0  dactylifera\n",
      "1          NaN\n",
      "2      phoenix\n",
      "3        √°rbol\n",
      "   0                    1\n",
      "0  1                  war\n",
      "1  2                 poor\n",
      "2  3  politic persecution\n",
      "                   war\n",
      "0                 poor\n",
      "1  politic persecution\n",
      "   0           1\n",
      "0  1       Flood\n",
      "1  2     dryness\n",
      "2  3  earthquake\n",
      "3  4       storm\n",
      "4  5       plage\n",
      "        Flood\n",
      "0     dryness\n",
      "1  earthquake\n",
      "2       storm\n",
      "3       plage\n",
      "   0        1         2        3               4  5\n",
      "0  1  27.4977  -7.82859  463.287          public  0\n",
      "1  2  27.4862  -7.82392  457.146  private__insid  0\n",
      "2  3  27.4947  -7.82842  455.606          public  0\n",
      "3  4      nan       nan      nan          public  0\n",
      "   27.49774864  -7.82858492  463.2865600586          public  0\n",
      "0    27.486246    -7.823924      457.145956  private__insid  0\n",
      "1    27.494720    -7.828418      455.605743          public  0\n",
      "2          NaN          NaN             NaN          public  0\n",
      "    0        1         2        3               4  5\n",
      "0   1  27.4957  -7.82382   521.69  private__insid  0\n",
      "1   2  27.4888  -7.82835  457.556          public  0\n",
      "2   3  27.4875  -7.83021  452.842          public  0\n",
      "3   4  27.4955  -7.82309  462.861  private__insid  0\n",
      "4   5  27.4996  -7.82461  468.409          public  0\n",
      "5   6  27.4974  -7.83321  466.942  private__insid  0\n",
      "6   7  27.4977  -7.83318  461.898  private__insid  0\n",
      "7   8  27.4912  -7.82552  451.052  private__insid  0\n",
      "8   9  40.3868  -3.69912      0.0          public  0\n",
      "9  10      nan       nan      nan  private__insid  0\n",
      "   27.495740346399998  -7.8238219655  521.6904296875  private__insid  0\n",
      "0           27.488802      -7.828352      457.556263          public  0\n",
      "1           27.487468      -7.830206      452.842218          public  0\n",
      "2           27.495528      -7.823089      462.861317  private__insid  0\n",
      "3           27.499611      -7.824611      468.409302          public  0\n",
      "4           27.497384      -7.833210      466.942444  private__insid  0\n",
      "5           27.497743      -7.833182      461.898041  private__insid  0\n",
      "6           27.491189      -7.825525      451.051514  private__insid  0\n",
      "7           40.386818      -3.699125        0.000000          public  0\n",
      "8                 NaN            NaN             NaN  private__insid  0\n",
      "    0  1     2     3     4     5     6     7     8     9     10    11    12 13\n",
      "0    1  1  None  None  None  None  None  None  None  None  None  None  None  1\n",
      "1    2  1  None  None  None  None  None  None  None  None  None  None  None  1\n",
      "2    3  1  None  None  None  None  None  None  None  None  None  None  None  1\n",
      "3    4  1  None  None  None  None  None  None  None  None  None  None  None  1\n",
      "4    5  1  None  None  None  None  None  None  None  None  None  None  None  1\n",
      "5    6  1  None  None  None  None  None  None  None  None  None  None  None  1\n",
      "6    7  1  None  None  None  None  None  None  None  None  None  None  None  1\n",
      "7    8  1  None  None  None  None  None  None  None  None  None  None  None  1\n",
      "8    9  1  None  None  None  None  None  None  None  None  None  None  None  1\n",
      "9   10  1  None  None  None  None  None  None  None  None  None  None  None  1\n",
      "10  11  1  None  None  None  None  None  None  None  None  None  None  None  1\n",
      "11  12  1  None  None  None  None  None  None  None  None  None  None  None  1\n",
      "    1\n",
      "0   1\n",
      "1   1\n",
      "2   1\n",
      "3   1\n",
      "4   1\n",
      "5   1\n",
      "6   1\n",
      "7   1\n",
      "8   1\n",
      "9   1\n",
      "10  1\n",
      "   0          1\n",
      "0  1       meat\n",
      "1  2      grain\n",
      "2  3  vegetable\n",
      "3  4      fruit\n",
      "        meat\n",
      "0      grain\n",
      "1  vegetable\n",
      "2      fruit\n",
      "   0                 1\n",
      "0  1  Humanitarian Aid\n",
      "1  2             Crops\n",
      "2  3            Market\n",
      "  Humanitarian Aid\n",
      "0            Crops\n",
      "1           Market\n",
      "   0           1\n",
      "0  1   Breakfast\n",
      "1  2       lunch\n",
      "2  3  coffe time\n",
      "3  4      dinner\n",
      "    Breakfast\n",
      "0       lunch\n",
      "1  coffe time\n",
      "2      dinner\n",
      "   0           1\n",
      "0  1     animals\n",
      "1  2     cereals\n",
      "2  3      fruits\n",
      "3  4        none\n",
      "4  5  vegetables\n",
      "      animals\n",
      "0     cereals\n",
      "1      fruits\n",
      "2        none\n",
      "3  vegetables\n",
      "   0                   1\n",
      "0  1                 one\n",
      "1  2                 two\n",
      "2  3               three\n",
      "3  4  Greater than three\n",
      "                  one\n",
      "0                 two\n",
      "1               three\n",
      "2  Greater than three\n",
      "   0        1\n",
      "0  1     pork\n",
      "1  2     beef\n",
      "2  3  chicken\n",
      "3  4     lamp\n",
      "4  5  cereals\n",
      "5  6  legumes\n",
      "6  7   fruits\n",
      "      pork\n",
      "0     beef\n",
      "1  chicken\n",
      "2     lamp\n",
      "3  cereals\n",
      "4  legumes\n",
      "5   fruits\n",
      "     0                                              1  \\\n",
      "0    1  Administration for Refugee and Returnee Affai   \n",
      "1    2  National Resource Development and Environment   \n",
      "2    3                     Ethiopian Electric Utility   \n",
      "3    4  Asociaci√≥n Espa√±ola de Cooperaci√≥n Internacio   \n",
      "4    5                                 IBERDROLA S.A.   \n",
      "5    6                 Fundaci√≥n ACCIONA Microenerg√≠a   \n",
      "6    7                                         itdUPM   \n",
      "7    8                                        Philips   \n",
      "8    9           International Rescue Committee (IRC)   \n",
      "9   10                Norwegian Refugee Council (NRC)   \n",
      "10  11                   Jesuit Refugee Service (JRS)   \n",
      "11  12             Centre of Victims of Torture (CVT)   \n",
      "12  13               Medecins Sans Frontieres (MSF-H)   \n",
      "13  14         Innovative Humanitarian Solutions (IHS   \n",
      "14  15                       World Food Program (WFP)   \n",
      "15  16  United Nations High Commissioner for Refugees   \n",
      "16  17         United Nations Childrens Fund (UNICEF)   \n",
      "17  18  International Organization for Migration (IOM   \n",
      "18  19    International Committee of RED Cross (ICRC)   \n",
      "19  20                     \"Ethiopian Orthodox Church   \n",
      "20  21  Opportunities Industrialization Centre - Ethi   \n",
      "\n",
      "                                                2  \n",
      "0                              Public Institution  \n",
      "1                              Public Institution  \n",
      "2                              Public Institution  \n",
      "3                              Public Institution  \n",
      "4                             Private Institution  \n",
      "5                             Private Institution  \n",
      "6                             Private Institution  \n",
      "7                             Private Institution  \n",
      "8                                             NGO  \n",
      "9                                             NGO  \n",
      "10                                            NGO  \n",
      "11                                            NGO  \n",
      "12                                            NGO  \n",
      "13                                            NGO  \n",
      "14                           International Agency  \n",
      "15                           International Agency  \n",
      "16                           International Agency  \n",
      "17                           International Agency  \n",
      "18                           International Agency  \n",
      "19   Development and Inter-Church Aid Department   \n",
      "20                                          Local  \n",
      "   Administration for Refugee and Returnee Affairs (ARRA)  \\\n",
      "0   National Resource Development and Environmenta...       \n",
      "1                          Ethiopian Electric Utility       \n",
      "2   Asociaci√≥n Espa√±ola de Cooperaci√≥n Internacion...       \n",
      "3                                      IBERDROLA S.A.       \n",
      "4                      Fundaci√≥n ACCIONA Microenerg√≠a       \n",
      "5                                              itdUPM       \n",
      "6                                             Philips       \n",
      "7                International Rescue Committee (IRC)       \n",
      "8                     Norwegian Refugee Council (NRC)       \n",
      "9                        Jesuit Refugee Service (JRS)       \n",
      "10                 Centre of Victims of Torture (CVT)       \n",
      "11                   Medecins Sans Frontieres (MSF-H)       \n",
      "12             Innovative Humanitarian Solutions (IHS       \n",
      "13                           World Food Program (WFP)       \n",
      "14  United Nations High Commissioner for Refugees ...       \n",
      "15             United Nations Childrens Fund (UNICEF)       \n",
      "16     International Organization for Migration (IOM)       \n",
      "17        International Committee of RED Cross (ICRC)       \n",
      "18  Ethiopian Orthodox Church, Development and Int...       \n",
      "19  Opportunities Industrialization Centre - Ethio...       \n",
      "\n",
      "      Public Institution  \n",
      "0     Public Institution  \n",
      "1     Public Institution  \n",
      "2     Public Institution  \n",
      "3    Private Institution  \n",
      "4    Private Institution  \n",
      "5    Private Institution  \n",
      "6    Private Institution  \n",
      "7                    NGO  \n",
      "8                    NGO  \n",
      "9                    NGO  \n",
      "10                   NGO  \n",
      "11                   NGO  \n",
      "12                   NGO  \n",
      "13  International Agency  \n",
      "14  International Agency  \n",
      "15  International Agency  \n",
      "16  International Agency  \n",
      "17  International Agency  \n",
      "18                 Local  \n",
      "19                 Local  \n",
      "   0       1\n",
      "0  1  Kunama\n",
      "Empty DataFrame\n",
      "Columns: [Kunama, Tigrinya, Saho]\n",
      "Index: []\n",
      "   0          1\n",
      "0  1  Trigrinya\n",
      "1  2      √Årabe\n",
      "2  3   Triginya\n",
      "3  4     Kunama\n",
      "  Trigrinya\n",
      "0     √Årabe\n",
      "1  Triginya\n",
      "2    Kunama\n",
      "   0                      1\n",
      "0  1                  Islam\n",
      "1  2  Cristianismo Ortodoxo\n",
      "2  3         Protestantismo\n",
      "3  4           Cristianismo\n",
      "4  5                 iIslam\n",
      "                   Islam\n",
      "0  Cristianismo Ortodoxo\n",
      "1         Protestantismo\n",
      "2           Cristianismo\n",
      "3                 iIslam\n",
      "   0                 1\n",
      "0  1           lantern\n",
      "1  2       light bulbs\n",
      "2  3      mobile phone\n",
      "3  4             radio\n",
      "4  5                tv\n",
      "5  6          computer\n",
      "6  7            fridge\n",
      "7  8  electrical stove\n",
      "8  9            others\n",
      "            lantern\n",
      "0       light bulbs\n",
      "1      mobile phone\n",
      "2             radio\n",
      "3                tv\n",
      "4          computer\n",
      "5            fridge\n",
      "6  electrical stove\n",
      "7            others\n",
      "   0                1\n",
      "0  1  electrical grid\n",
      "1  2    diesel genset\n",
      "2  3      solar panel\n",
      "3  4            other\n",
      "  electrical grid\n",
      "0   diesel genset\n",
      "1     solar panel\n",
      "2           other\n",
      "   0           1\n",
      "0  1     walking\n",
      "1  2  motrocycle\n",
      "2  3        bike\n",
      "3  4       truck\n",
      "4  5      animal\n",
      "5  6         car\n",
      "      walking\n",
      "0  motrocycle\n",
      "1        bike\n",
      "2       truck\n",
      "3      animal\n",
      "4         car\n",
      "     0  1  2  3  4  5\n",
      "0    1  1  0  1  1  1\n",
      "1    2  1  1  1  1  1\n",
      "2    3  1  1  1  1  0\n",
      "3    4  1  1  1  1  1\n",
      "4    5  1  1  1  1  1\n",
      "5    6  1  0  1  1  0\n",
      "6    7  1  1  1  1  1\n",
      "7    8  0  0  0  0  0\n",
      "8    9  1  1  1  1  1\n",
      "9   10  1  1  1  1  1\n",
      "10  11  1  0  1  1  1\n",
      "11  12  1  1  1  1  1\n",
      "12  13  0  0  1  1  1\n",
      "13  14  1  1  1  1  1\n",
      "14  15  1  1  1  1  1\n",
      "15  16  1  1  1  1  1\n",
      "16  17  1  1  1  1  0\n",
      "17  18  1  1  1  1  0\n",
      "18  19  1  1  1  1  0\n",
      "19  20  1  1  1  1  1\n",
      "20  21  1  1  1  1  1\n",
      "21  22  1  1  1  1  1\n",
      "22  23  1  1  1  1  1\n",
      "23  24  1  1  1  1  1\n",
      "24  25  1  0  1  1  1\n",
      "25  26  1  1  1  1  1\n",
      "26  27  1  1  1  1  1\n",
      "27  28  1  1  1  1  0\n",
      "28  29  1  1  1  1  1\n",
      "29  30  0  0  0  0  0\n",
      "30  31  1  1  1  1  0\n",
      "31  32  1  1  1  1  1\n",
      "32  33  1  0  0  0  0\n",
      "33  34  0  0  0  0  0\n",
      "34  35  1  0  0  0  0\n",
      "35  36  0  0  0  0  0\n",
      "36  37  0  0  0  0  0\n",
      "    1  0  1.1  1.2  1.3\n",
      "0   1  1    1    1    1\n",
      "1   1  1    1    1    0\n",
      "2   1  1    1    1    1\n",
      "3   1  1    1    1    1\n",
      "4   1  0    1    1    0\n",
      "5   1  1    1    1    1\n",
      "6   0  0    0    0    0\n",
      "7   1  1    1    1    1\n",
      "8   1  1    1    1    1\n",
      "9   1  0    1    1    1\n",
      "10  1  1    1    1    1\n",
      "11  0  0    1    1    1\n",
      "12  1  1    1    1    1\n",
      "13  1  1    1    1    1\n",
      "14  1  1    1    1    1\n",
      "15  1  1    1    1    0\n",
      "16  1  1    1    1    0\n",
      "17  1  1    1    1    0\n",
      "18  1  1    1    1    1\n",
      "19  1  1    1    1    1\n",
      "20  1  1    1    1    1\n",
      "21  1  1    1    1    1\n",
      "22  1  1    1    1    1\n",
      "23  1  0    1    1    1\n",
      "24  1  1    1    1    1\n",
      "25  1  1    1    1    1\n",
      "26  1  1    1    1    0\n",
      "27  1  1    1    1    1\n",
      "28  0  0    0    0    0\n",
      "29  1  1    1    1    0\n",
      "30  1  1    1    1    1\n",
      "31  1  0    0    0    0\n",
      "32  0  0    0    0    0\n",
      "33  1  0    0    0    0\n",
      "34  0  0    0    0    0\n",
      "35  0  0    0    0    0\n",
      "    0          1\n",
      "0   1   WhatsApp\n",
      "1   2   Facebook\n",
      "2   3      Skype\n",
      "3   4  Instagram\n",
      "4   5     Google\n",
      "5   6    Youtube\n",
      "6   7      Email\n",
      "7   8       Word\n",
      "8   9      Excel\n",
      "9  10       Otra\n",
      "    WhatsApp\n",
      "0   Facebook\n",
      "1      Skype\n",
      "2  Instagram\n",
      "3     Google\n",
      "4    Youtube\n",
      "5      Email\n",
      "6       Word\n",
      "7      Excel\n",
      "8       Otra\n",
      "   0     1     2     3    4  5     6\n",
      "0  1  None  None  None  yes  0  None\n",
      "1  2  None  None  None   no  0  None\n",
      "   Unnamed: 0  Unnamed: 1  Unnamed: 2 yes yes.1\n",
      "0         NaN         NaN         NaN  no    no\n",
      "   0       1\n",
      "0  1  mobile\n",
      "1  2     nan\n",
      "   mobile\n",
      "0     NaN\n",
      "    0              1                   2      3               4       5   \\\n",
      "0    1           None                None    nan       secundary   985.0   \n",
      "1    2           None                None    nan         nursery   338.0   \n",
      "2    3           None                None    nan         primary   715.0   \n",
      "3    4           None                None    nan  vocational_tra    20.0   \n",
      "4    5  27.4892331723       -7.8294352113  455.0       secundary  1200.0   \n",
      "5    6  27.4939763502       -7.8329171673  460.0         nursery   280.0   \n",
      "6    7  27.4982200615  -7.833721182100001  464.0         primary     nan   \n",
      "7    8           None                None    nan         nursery    10.0   \n",
      "8    9           None                None    nan         nursery    20.0   \n",
      "9   10           None                None    nan       secundary    90.0   \n",
      "10  11           None                None    nan  vocational_tra    90.0   \n",
      "11  12    40.28116763         -3.80719204  758.0         nursery    60.0   \n",
      "12  13           None                None    nan         nursery    60.0   \n",
      "13  14           None                None    nan         nursery    60.0   \n",
      "14  15           None                None    nan         nursery    60.0   \n",
      "15  16           None                None    nan  vocational_tra    90.0   \n",
      "16  17           None                None    nan  vocational_tra    60.0   \n",
      "\n",
      "      6     7                 8                          9   \\\n",
      "0   16.0  33.0  books__noteboo_2  0 days 08:00:00.000000000   \n",
      "1    4.0  15.0    notebook_and_p  0 days 08:00:00.000000000   \n",
      "2   15.0  22.0    books__noteboo  0 days 07:00:00.000000000   \n",
      "3    7.0   1.0              None  0 days 07:00:00.000000000   \n",
      "4   12.0  38.0  books__noteboo_3  0 days 07:00:00.000000000   \n",
      "5   10.0  20.0    notebook_and_p  0 days 07:30:00.000000000   \n",
      "6    3.0  20.0    books__noteboo  0 days 07:30:00.000000000   \n",
      "7   10.0   5.0    notebook_and_p  0 days 07:00:00.000000000   \n",
      "8   12.0   7.0    books__noteboo  0 days 07:00:00.000000000   \n",
      "9    nan   7.0    notebook_and_p                        NaT   \n",
      "10   9.0   nan  books__noteboo_2  0 days 07:00:00.000000000   \n",
      "11  10.0   7.0    notebook_and_p  0 days 07:00:00.000000000   \n",
      "12   5.0   5.0    books__noteboo  0 days 07:00:00.000000000   \n",
      "13   5.0   7.0    books__noteboo  0 days 07:00:00.000000000   \n",
      "14  10.0   9.0    notebook_and_p  0 days 07:00:00.000000000   \n",
      "15  15.0   5.0  books__noteboo_2  0 days 07:00:00.000000000   \n",
      "16   5.0   9.0              None                        NaT   \n",
      "\n",
      "                           10 11  \n",
      "0   0 days 13:45:00.000000000  0  \n",
      "1   0 days 12:00:00.000000000  0  \n",
      "2   0 days 12:15:00.000000000  0  \n",
      "3   0 days 13:00:00.000000000  0  \n",
      "4   0 days 13:00:00.000000000  0  \n",
      "5   0 days 11:40:00.000000000  0  \n",
      "6   0 days 13:10:00.000000000  0  \n",
      "7   0 days 11:00:00.000000000  0  \n",
      "8   0 days 11:00:00.000000000  0  \n",
      "9   0 days 00:00:00.000000000  0  \n",
      "10  0 days 12:00:00.000000000  0  \n",
      "11  0 days 11:00:00.000000000  0  \n",
      "12  0 days 11:00:00.000000000  0  \n",
      "13  0 days 11:00:00.000000000  0  \n",
      "14  0 days 11:00:00.000000000  0  \n",
      "15  0 days 13:00:00.000000000  0  \n",
      "16  0 days 00:00:00.000000000  0  \n",
      "    Unnamed: 0  Unnamed: 1  Unnamed: 2       secundary   985.0  16.0  33.0  \\\n",
      "0          NaN         NaN         NaN         nursery   338.0   4.0  15.0   \n",
      "1          NaN         NaN         NaN         primary   715.0  15.0  22.0   \n",
      "2          NaN         NaN         NaN  vocational_tra    20.0   7.0   1.0   \n",
      "3    27.489233   -7.829435  455.467913       secundary  1200.0  12.0  38.0   \n",
      "4    27.493976   -7.832917  460.191193         nursery   280.0  10.0  20.0   \n",
      "5    27.498220   -7.833721  464.280121         primary     NaN   3.0  20.0   \n",
      "6          NaN         NaN         NaN         nursery    10.0  10.0   5.0   \n",
      "7          NaN         NaN         NaN         nursery    20.0  12.0   7.0   \n",
      "8          NaN         NaN         NaN       secundary    90.0   NaN   7.0   \n",
      "9          NaN         NaN         NaN  vocational_tra    90.0   9.0   NaN   \n",
      "10   40.281168   -3.807192  758.000000         nursery    60.0  10.0   7.0   \n",
      "11         NaN         NaN         NaN         nursery    60.0   5.0   5.0   \n",
      "12         NaN         NaN         NaN         nursery    60.0   5.0   7.0   \n",
      "13         NaN         NaN         NaN         nursery    60.0  10.0   9.0   \n",
      "14         NaN         NaN         NaN  vocational_tra    90.0  15.0   5.0   \n",
      "15         NaN         NaN         NaN  vocational_tra    60.0   5.0   9.0   \n",
      "\n",
      "    books__noteboo_2  08:00:00  13:45:00  \n",
      "0     notebook_and_p  08:00:00  12:00:00  \n",
      "1     books__noteboo  07:00:00  12:15:00  \n",
      "2                NaN  07:00:00  13:00:00  \n",
      "3   books__noteboo_3  07:00:00  13:00:00  \n",
      "4     notebook_and_p  07:30:00  11:40:00  \n",
      "5     books__noteboo  07:30:00  13:10:00  \n",
      "6     notebook_and_p  07:00:00  11:00:00  \n",
      "7     books__noteboo  07:00:00  11:00:00  \n",
      "8     notebook_and_p       NaN       NaN  \n",
      "9   books__noteboo_2  07:00:00  12:00:00  \n",
      "10    notebook_and_p  07:00:00  11:00:00  \n",
      "11    books__noteboo  07:00:00  11:00:00  \n",
      "12    books__noteboo  07:00:00  11:00:00  \n",
      "13    notebook_and_p  07:00:00  11:00:00  \n",
      "14  books__noteboo_2  07:00:00  13:00:00  \n",
      "15               NaN       NaN       NaN  \n",
      "   0     1     2     3   4     5  6\n",
      "0  1  None  None  None  30  None  0\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, Unnamed: 1, Unnamed: 2, 30.0]\n",
      "Index: []\n",
      "   0               1\n",
      "0  1  economic_issue\n",
      "1  2         illness\n",
      "2  3  long_distance_\n",
      "3  4             nan\n",
      "4  5            work\n",
      "   economic_issue\n",
      "0         illness\n",
      "1  long_distance_\n",
      "2             NaN\n",
      "3            work\n",
      "   0        1         2        3                                4  \\\n",
      "0  1  27.4607  -8.17412  441.738                             None   \n",
      "1  2  27.4615   -8.1736  445.037  Nave crianza de pollos (desuso)   \n",
      "2  3  27.4978  -7.82855  461.468       Hacen ladrillos de cemento   \n",
      "3  4      nan       nan      nan                          Library   \n",
      "\n",
      "                             5     6  \n",
      "0  Matadero desuso (en Nhaila)  None  \n",
      "1                    En Nhaila  None  \n",
      "2                           Lo  None  \n",
      "3                  Biblioteca1  None  \n",
      "   27.46065982  -8.17411701  441.73779296879997  \\\n",
      "0    27.461491    -8.173601          445.036621   \n",
      "1    27.497802    -7.828554          461.468445   \n",
      "2          NaN          NaN                 NaN   \n",
      "\n",
      "                        Unnamed: 3 Matadero desuso (en Nhaila)  \n",
      "0  Nave crianza de pollos (desuso)                   En Nhaila  \n",
      "1       Hacen ladrillos de cemento                          Lo  \n",
      "2                          Library                 Biblioteca1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0        1         2        3     4  5\n",
      "0  1   27.497  -7.82312  462.693  None  0\n",
      "1  2  27.4939  -7.83313   449.42  None  0\n",
      "2  3  27.4895  -7.82294   440.56  None  0\n",
      "   27.4969495108  -7.8231217190999995  462.69347966830003\n",
      "0      27.493946            -7.833126          449.419830\n",
      "1      27.489517            -7.822940          440.560455\n",
      "   0            1\n",
      "0  1   Phone Call\n",
      "1  2     Internet\n",
      "2  3           PC\n",
      "3  4  Programming\n",
      "    Phone Call\n",
      "0     Internet\n",
      "1           PC\n",
      "2  Programming\n",
      "   0              1\n",
      "0  1  vegetal_waste\n",
      "1  2  vegetal_waste\n",
      "2  3          paper\n",
      "   vegetal_waste\n",
      "0  vegetal_waste\n",
      "1          paper\n",
      "   0        1\n",
      "0  1  trabajo\n",
      "Empty DataFrame\n",
      "Columns: [trabajo]\n",
      "Index: []\n",
      "   0          1\n",
      "0  1       food\n",
      "1  2    clothes\n",
      "2  3      water\n",
      "3  4  education\n",
      "4  5  transport\n",
      "5  6     health\n",
      "6  7     energy\n",
      "        food\n",
      "0    clothes\n",
      "1      water\n",
      "2  education\n",
      "3  transport\n",
      "4     health\n",
      "5     energy\n",
      "     0            1\n",
      "0    1       others\n",
      "1    2  remittances\n",
      "2    3    livestock\n",
      "3    4    subsidies\n",
      "4    5     commerce\n",
      "5    6    subsidies\n",
      "6    7       others\n",
      "7    8    subsidies\n",
      "8    9       others\n",
      "9   10    subsidies\n",
      "10  11       others\n",
      "11  12     commerce\n",
      "12  13       others\n",
      "13  14    subsidies\n",
      "14  15    subsidies\n",
      "15  16    subsidies\n",
      "16  17       others\n",
      "17  18       others\n",
      "18  19       others\n",
      "19  20       others\n",
      "20  21      nothing\n",
      "21  22    subsidies\n",
      "22  23    subsidies\n",
      "         others\n",
      "0   remittances\n",
      "1     livestock\n",
      "2     subsidies\n",
      "3      commerce\n",
      "4     subsidies\n",
      "5        others\n",
      "6     subsidies\n",
      "7        others\n",
      "8     subsidies\n",
      "9        others\n",
      "10     commerce\n",
      "11       others\n",
      "12    subsidies\n",
      "13    subsidies\n",
      "14    subsidies\n",
      "15       others\n",
      "16       others\n",
      "17       others\n",
      "18       others\n",
      "19      nothing\n",
      "20    subsidies\n",
      "21    subsidies\n",
      "     0                      1\n",
      "0    1                 energy\n",
      "1    2                shelter\n",
      "2    3           water access\n",
      "3    4             sanitation\n",
      "4    5              education\n",
      "5    6                 health\n",
      "6    7           public space\n",
      "7    8                   food\n",
      "8    9                    TIC\n",
      "9   10                   work\n",
      "10  11       waste management\n",
      "11  12       public transport\n",
      "12  13       religious center\n",
      "13  14  socio cultural center\n",
      "14  15                 market\n",
      "                   energy\n",
      "0                 shelter\n",
      "1            water access\n",
      "2              sanitation\n",
      "3               education\n",
      "4                  health\n",
      "5            public space\n",
      "6                    food\n",
      "7                     TIC\n",
      "8                    work\n",
      "9        waste management\n",
      "10       public transport\n",
      "11       religious center\n",
      "12  socio cultural center\n",
      "13                 market\n",
      "   0                1\n",
      "0  1   Street_morning\n",
      "1  2     Street_Night\n",
      "2  3        Bath_Area\n",
      "3  4    Latrine_Night\n",
      "4  5       Open_Space\n",
      "5  6        Work_Area\n",
      "6  7    Shelter_Night\n",
      "7  8  Shelter_Morning\n",
      "    Street_morning\n",
      "0     Street_Night\n",
      "1        Bath_Area\n",
      "2    Latrine_Night\n",
      "3       Open_Space\n",
      "4        Work_Area\n",
      "5    Shelter_Night\n",
      "6  Shelter_Morning\n",
      "   0                    1\n",
      "0  1  Firewood Collection\n",
      "1  2              Cooking\n",
      "  Firewood Collection\n",
      "0             Cooking\n",
      "   0                 1\n",
      "0  1        Shade Area\n",
      "1  2   Urban Furniture\n",
      "2  3        Paved Area\n",
      "3  4  Waste Management\n",
      "         Shade Area\n",
      "0   Urban Furniture\n",
      "1        Paved Area\n",
      "2  Waste Management\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#f = open('LoadDataCamp.sql','w+')\n",
    "\n",
    "tablesNM = pd.read_csv(\"NMtablesCamp.csv\")\n",
    "tablesNM = np.array(tablesNM)\n",
    "tables = np.array([])\n",
    "originTables = np.array([])\n",
    "for column in tablesNM:\n",
    "    for elem in column:\n",
    "        x = getTableName(elem)\n",
    "        if(is_non_zero_file(getPath(finalpath,x+\".csv\"))):\n",
    "            table = pd.DataFrame(selectAll(x,elem))\n",
    "            communityFK = get_communityFK(elem)\n",
    "            arrayTable = np.array([])\n",
    "            arrayCommunity = np.array([])\n",
    "            for index, row in table.iterrows():\n",
    "                tableFK = get_tableFK(table, index)\n",
    "                arrayTable = np.append(arrayTable,tableFK)\n",
    "                arrayCommunity = np.append(arrayCommunity,communityFK[0][0])\n",
    "            tableNM = concatDF((pd.DataFrame(arrayTable)),(pd.DataFrame(arrayCommunity)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
