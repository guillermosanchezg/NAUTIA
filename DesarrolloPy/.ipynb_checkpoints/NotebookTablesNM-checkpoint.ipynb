{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 21 12:34:54 2020\n",
    "\n",
    "@author: guill\n",
    "\"\"\"\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "#pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "#import nltk\n",
    "#nltk.download(\"popular\") # required to download the stopwords lists\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "#spanish_stopwords = stopwords.words('spanish')\n",
    "#english_stopwords = stopwords.words('english')\n",
    "\n",
    "originalpath = \"C:/Users/guill/Documents/Universidad/PlataformaRefugiados/NAUTIA/DesarrolloPy/DataSetOriginales\"\n",
    "finalpath = \"C:/Users/guill/Documents/Universidad/PlataformaRefugiados/NAUTIA/DesarrolloPy/DataSetFinales\"\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  port = 3309,\n",
    "  host=\"127.0.0.1\",\n",
    "  user=\"root\",\n",
    "  passwd=\"\",\n",
    "  database = 'nautiatoolkit'\n",
    ")\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "def is_non_zero_file(fpath):\n",
    "    return os.path.isfile(fpath) and os.path.getsize(fpath)\n",
    "\n",
    "def getTableName(elem):\n",
    "    if(elem.find(\"_has_camp\") != -1):\n",
    "        x = elem.replace(\"_has_camp\",\"\")\n",
    "    else:\n",
    "        if(elem.find(\"_has_country\") != -1):\n",
    "            x = elem.replace(\"_has_country\",\"\")\n",
    "        else:\n",
    "            if(elem.find(\"_has_community\") != -1):\n",
    "                x = elem.replace(\"_has_community\",\"\")\n",
    "    return x\n",
    "\n",
    "#AQUIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "\n",
    "def get_communityPK(elem):\n",
    "    if(elem.find(\"_has_camp\") != -1):\n",
    "        cursor.execute(\"SELECT idCamp FROM camp ORDER BY idCamp DESC LIMIT 1\")\n",
    "    else:\n",
    "        if(elem.find(\"_has_country\") != -1):\n",
    "            cursor.execute(\"SELECT idCountry FROM Country ORDER BY idCountry DESC LIMIT 1\")\n",
    "        else:\n",
    "            if(elem.find(\"_has_community\") != -1):\n",
    "                cursor.execute(\"SELECT idCommunity FROM community ORDER BY idCommunity DESC LIMIT 1\")\n",
    "    return cursor.fetchall()\n",
    "\n",
    "def get_tableFK(df,index):\n",
    "    array = np.array(df)\n",
    "    return array[index][0]\n",
    "\n",
    "\n",
    "def fixBibliography(df):\n",
    "    df = dfFix(df,\"GENERAL INFORMATION - COUNTRY LEVEL\")\n",
    "    df.columns = ['GeneralInfo', 'CommunityCountry', 'RefugeeCountry']\n",
    "    df.set_index('GeneralInfo', inplace = True)\n",
    "    df = df.transpose()\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def dfFix(df,col1 = False,col2 = False):\n",
    "    result = df.copy()\n",
    "    if(col1):\n",
    "        x = result.columns.get_loc(col1)\n",
    "        result.drop(result.columns[0:x],axis = 1, inplace = True)\n",
    "    if(col2):\n",
    "        y = result.columns.get_loc(col2)\n",
    "        result.drop(result.columns[y:],axis = 1, inplace = True)\n",
    "    return result\n",
    "\n",
    "def validColumn(cad):\n",
    "    result = False\n",
    "    if(cad == \"index\"):#Population\n",
    "        result = True\n",
    "    else:\n",
    "        if(cad == \"Type_of_settlement\"):\n",
    "            result = True\n",
    "        else:\n",
    "            if(cad == \"General:settlement\"):\n",
    "                result = True\n",
    "            else:\n",
    "                if(cad == \"general_info:_1_1_Choose_the_settlement\"):\n",
    "                    result = True\n",
    "                else:\n",
    "                    if(cad == \"General_Information:Type_of_setlement\"):\n",
    "                        result = True\n",
    "                    else:\n",
    "                        if(cad == \"General:Settlement\"):\n",
    "                            result = True\n",
    "                        else:\n",
    "                            if(cad == \"Type_of_setlement\"):\n",
    "                                result = True\n",
    "    return result\n",
    "\n",
    "def specialTable(cad):\n",
    "    result = False\n",
    "    if(cad == \"s_educationalcenter\"):\n",
    "        result = True\n",
    "    else:\n",
    "        if(cad == \"s_primaryattention\"):\n",
    "            result = True\n",
    "        else:\n",
    "            if(cad == \"s_hospital\"):\n",
    "                result = True\n",
    "    return result\n",
    "\n",
    "def dropRow(df,i):\n",
    "    return df.drop(index = i)\n",
    "\n",
    "def get_communityRows(df,cad,communityType): #la funci√≥n pd.loc[] tiene un bug indiscriminado (https://github.com/pandas-dev/pandas/issues/8555)\n",
    "    result = df\n",
    "    if(communityType == 0):\n",
    "        comm = \"host_community\"\n",
    "    else:\n",
    "        comm = \"refugee_camp\"\n",
    "    for index, row in df.iterrows():\n",
    "        if(row[cad] != comm):\n",
    "            result = dropRow(result,index)\n",
    "    return result\n",
    "\n",
    "def setDataByIndex(df,communityType):\n",
    "    array = df.columns\n",
    "    i = 0\n",
    "    df = df.replace(\"refugee\",\"refugee_camp\")\n",
    "    df = df.replace(\"host_comunity\",\"host_community\")\n",
    "    df = df.replace(\"RefugeeCountry\",\"refugee_camp\")\n",
    "    df = df.replace(\"CommunityCountry\",\"host_community\")\n",
    "    while(validColumn(array[i]) == False):\n",
    "        i += 1\n",
    "    df = get_communityRows(df,array[i],communityType)\n",
    "    return df\n",
    "\n",
    "def set_AllCSVtoDF(communityType):\n",
    "    Bibliography = pd.read_excel(getPath(originalpath,\"Bibliography_120220.xlsx\"))\n",
    "    Bibliography = fixBibliography(Bibliography)\n",
    "    Bibliography = setDataByIndex(Bibliography,communityType)\n",
    "    Entities = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Entities_Interview_results.csv\")),communityType)\n",
    "    LocalLeaders = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Local_leaders_v3_results.csv\")),communityType)\n",
    "    HouseHold = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Survey_household_v6_results.csv\")),communityType)\n",
    "    WomenGroup = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Women_Focus_Group2_results.csv\")),communityType)\n",
    "    SanitationInfra = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_V1_0_Sanitation_Infrastructre_results.csv\")),communityType)\n",
    "    Priorities = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Priorities_v3_results.csv\")),communityType)\n",
    "    GeneralForm = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_General_form_v3_results.csv\")),communityType)\n",
    "    PublicSpace = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Public_Space_results.csv\")),communityType)\n",
    "    WaterInf = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Water_Infrastructure_results.csv\")),communityType)\n",
    "    SanitationInf = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_V1_0_Sanitation_Infrastructre_results.csv\")),communityType)\n",
    "    WasteManagementInf = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Waste_Management_Infrastructure_results.csv\")),communityType)\n",
    "    EnergyINF = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Energy_Infrastructure_results.csv\")),communityType)\n",
    "    Business = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA1_0_Business_surveys_v3_results.csv\")),communityType)\n",
    "    MobilityINF = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0__Transport_servicesaccess_points_results.csv\")),communityType) \n",
    "    ComunalServices = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Communal_Services_results.csv\")),communityType) \n",
    "    GeneralCitizen = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_General_Citizen_Focus_Group_results.csv\")),communityType)\n",
    "    Shelter = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Shelter_results.csv\")),communityType)\n",
    "    FarmyardCrop = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Farmyard_and_Crops_results.csv\")),communityType)\n",
    "    return Bibliography,Entities,LocalLeaders,HouseHold,WomenGroup,SanitationInfra,Priorities,GeneralForm,PublicSpace,WaterInf,EnergyINF,SanitationInf,WasteManagementInf,EnergyINF,Business,MobilityINF,ComunalServices,GeneralCitizen,Shelter,FarmyardCrop\n",
    "\n",
    "def concatDF(df1,df2):\n",
    "    return  pd.concat([df1,df2],axis = 1, ignore_index = True, sort = True)\n",
    "\n",
    "def mkCSV(df,fileName):\n",
    "    df = df.dropna(how = 'all')\n",
    "    df *= 1   \n",
    "    fileName = fileName.lower()\n",
    "    df.to_csv('DataSetFinales/'+fileName,sep=',',header = False, index=False, encoding='utf-8')\n",
    "    \n",
    "def getPath(mainpath,filename):\n",
    "    return os.path.join(mainpath, filename)\n",
    "\n",
    "def getSubColumnNames(df,x):\n",
    "    columns = df.columns\n",
    "    array = []\n",
    "    for column in columns:\n",
    "        column = column[x:]\n",
    "        array.append(column)\n",
    "    return pd.DataFrame(array) \n",
    "\n",
    "def addInstitutionAndType(df,array1,array2,instType):\n",
    "    df = df.dropna(axis = 1)\n",
    "    df = np.array(df)\n",
    "    for row in df:\n",
    "        for elem in row:\n",
    "            array1 = np.append(array1,elem)\n",
    "            array2 = np.append(array2,instType)\n",
    "    return array1,array2\n",
    "\n",
    "def politicalActor(df1,df2,df3,df4,df5):\n",
    "    institution = []\n",
    "    instType = []\n",
    "\n",
    "    institution, instType  = addInstitutionAndType(df1,institution,instType,'Public Institution')\n",
    "    institution, instType  = addInstitutionAndType(df2,institution,instType,'Private Institution')\n",
    "    institution, instType  = addInstitutionAndType(df3,institution,instType,'NGO')\n",
    "    institution, instType  = addInstitutionAndType(df4,institution,instType,'International Agency')\n",
    "    institution, instType  = addInstitutionAndType(df5,institution,instType,'Local')\n",
    "\n",
    "    institution = pd.DataFrame(institution)\n",
    "    institution = institution.reset_index(drop = True)\n",
    "    instType = pd.DataFrame(instType)\n",
    "    instType = instType.reset_index(drop = True)\n",
    "    \n",
    "    return concatDF(institution,instType)\n",
    "\n",
    "\n",
    "def get_claveValor(df1,df2):\n",
    "    array1 = np.array(df2)\n",
    "    array2 = np.array(df1)\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    i = 0\n",
    "    for row in array1:\n",
    "        var = array2[i]\n",
    "        for elem in row:\n",
    "            result1 = np.append(result1,elem)\n",
    "            result2 = np.append(result2,var)\n",
    "        i+=1\n",
    "    result2 = pd.DataFrame(result2)\n",
    "    result2 = result2.reset_index(drop = True)\n",
    "    result1 = pd.DataFrame(result1)\n",
    "    result1 = result1.reset_index(drop = True)\n",
    "    return concatDF(result2,result1)\n",
    "\n",
    "def get_number(df):\n",
    "    df = np.array(df)\n",
    "    array = np.array([])\n",
    "    for column in df:\n",
    "        for elem in column:\n",
    "            array = np.append(array,elem)\n",
    "    return (pd.DataFrame(array)).fillna(0) \n",
    "\n",
    "def get_valueBySector(df1,df2):\n",
    "    df2 = df2.reset_index()\n",
    "    array1 = np.array(df1)\n",
    "    i = 0\n",
    "    for row in array1:\n",
    "        for elem in row:\n",
    "            if(elem == False):\n",
    "                df2 = dropRow(df2,i)\n",
    "        i += 1\n",
    "    df2 = df2.set_index('index')\n",
    "    return df2\n",
    "\n",
    "\n",
    "def separateValues(df):\n",
    "    if(df.isnull().values.all(axis=0)):\n",
    "        result = df\n",
    "    else:\n",
    "        array = np.array(df)\n",
    "        count_vectorizer = CountVectorizer(stop_words = spanish_stopwords+english_stopwords)\n",
    "        corpus = []\n",
    "        for row in array:\n",
    "            for elem in row:\n",
    "                corpus = np.append(corpus,[elem])\n",
    "        X = count_vectorizer.fit_transform(corpus)\n",
    "        array = count_vectorizer.get_feature_names()\n",
    "        result = pd.DataFrame(array)\n",
    "    return result\n",
    "\n",
    "def vectorizeValue(df):\n",
    "    df = separateValues(df)\n",
    "    year = np.array(['january','february','march','april','may','june','july','august','september','october','november','december'])\n",
    "    result = np.array([],dtype = bool)\n",
    "    df = np.array(df)\n",
    "    for elem in year:\n",
    "        flag = False\n",
    "        for column in df:\n",
    "            for month in column:\n",
    "                if(column == elem):\n",
    "                    flag = True\n",
    "        if(flag):\n",
    "            result = np.append(result,True)\n",
    "        else:\n",
    "            result = np.append(result,False)\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "def set_sector(df,sect, concat = True):\n",
    "    sector = np.array([])\n",
    "    df = df.dropna(how = 'all')\n",
    "    df = np.array(df)\n",
    "    for column in df:\n",
    "        sector = np.append(sector,sect)\n",
    "    sector = pd.DataFrame(sector)\n",
    "    df = pd.DataFrame(df)\n",
    "    if(concat):\n",
    "        result = concatDF(sector,df)\n",
    "    else:\n",
    "        result = sector\n",
    "    return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEducationalCenter(cad):\n",
    "    result = False\n",
    "    if(cad == \"s_educationalcenter\"):\n",
    "        result = True\n",
    "    return result\n",
    "\n",
    "def replacestr(df,cad1,cad2):\n",
    "    cols=list(df.columns)\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(str).str.replace(cad1,cad2)\n",
    "    return df\n",
    "\n",
    "def uniFormatTable(df):\n",
    "    df = replacestr(df,\"\\r\",\"\")\n",
    "    df = replacestr(df,\"NaN\",\"nan\")\n",
    "    df = replacestr(df,\"None\",\"nan\")\n",
    "    return df\n",
    "\n",
    "def uniFormatDF(df):\n",
    "    df = replacestr(df,\"NaN\",\"nan\")\n",
    "    df = replacestr(df,\"None\",\"nan\")\n",
    "    return df\n",
    "\n",
    "def get_tablePK(table,community):\n",
    "    cursor.execute(\"SELECT * FROM \"+table)\n",
    "    df1 = uniFormatTable(pd.DataFrame(cursor.fetchall()))\n",
    "    df2 = pd.read_csv(getPath(finalpath,table+\".csv\"),header = None, float_precision = \"high\")\n",
    "    df2 = uniFormatDF(df2)\n",
    "    df1 = np.array(df1)\n",
    "    pk = np.array([])\n",
    "    for index, row in df2.iterrows():\n",
    "        if(specialTable(table) == False):\n",
    "            if((np.equal(np.array(row),df1[index][1:])).all()):\n",
    "                pk = np.append(pk,df1[index][0])\n",
    "        else:\n",
    "            if(isEducationalCenter(table) == False):\n",
    "                if((np.equal(np.array(row),df1[index][1:-1])).all()):\n",
    "                    pk = np.append(pk,df1[index][0])\n",
    "            else:\n",
    "                if((np.equal(np.array(row[:-2]),df1[index][1:-3])).all()):\n",
    "                    pk = np.append(pk,df1[index][0])            \n",
    "    return pd.DataFrame(pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1\n",
      "0  1  2.0\n",
      "1  2  2.0\n",
      "   0    1\n",
      "0  1  2.0\n",
      "1  2  2.0\n",
      "2  3  2.0\n",
      "   0    1\n",
      "0  1  2.0\n",
      "1  2  2.0\n",
      "2  3  2.0\n",
      "3  4  2.0\n",
      "4  5  2.0\n",
      "   0    1\n",
      "0  1  2.0\n",
      "1  2  2.0\n",
      "2  3  2.0\n",
      "   0    1\n",
      "0  1  2.0\n",
      "1  2  2.0\n",
      "2  3  2.0\n",
      "3  4  2.0\n",
      "4  5  2.0\n",
      "   0    1\n",
      "0  1  2.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "    0    1\n",
      "0   1  1.0\n",
      "1   2  1.0\n",
      "2   3  1.0\n",
      "3   4  1.0\n",
      "4   5  1.0\n",
      "5   6  1.0\n",
      "6   7  1.0\n",
      "7   8  1.0\n",
      "8   9  1.0\n",
      "9  10  1.0\n",
      "Empty DataFrame\n",
      "Columns: [0, 1]\n",
      "Index: []\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "4  5  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "4  5  1.0\n",
      "5  6  1.0\n",
      "6  7  1.0\n",
      "     0    1\n",
      "0    3  1.0\n",
      "1    5  1.0\n",
      "2    6  1.0\n",
      "3    7  1.0\n",
      "4    8  1.0\n",
      "5    9  1.0\n",
      "6   10  1.0\n",
      "7   11  1.0\n",
      "8   12  1.0\n",
      "9   13  1.0\n",
      "10  14  1.0\n",
      "11  15  1.0\n",
      "12  17  1.0\n",
      "13  19  1.0\n",
      "Empty DataFrame\n",
      "Columns: [0, 1]\n",
      "Index: []\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "4  5  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "4  5  1.0\n",
      "5  6  1.0\n",
      "6  7  1.0\n",
      "7  8  1.0\n",
      "8  9  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "4  5  1.0\n",
      "5  6  1.0\n",
      "     0    1\n",
      "0    1  1.0\n",
      "1    2  1.0\n",
      "2    3  1.0\n",
      "3    4  1.0\n",
      "4    5  1.0\n",
      "5    6  1.0\n",
      "6    7  1.0\n",
      "7    8  1.0\n",
      "8    9  1.0\n",
      "9   10  1.0\n",
      "10  11  1.0\n",
      "11  12  1.0\n",
      "12  13  1.0\n",
      "13  14  1.0\n",
      "14  15  1.0\n",
      "15  16  1.0\n",
      "16  17  1.0\n",
      "17  18  1.0\n",
      "18  19  1.0\n",
      "19  20  1.0\n",
      "20  21  1.0\n",
      "21  22  1.0\n",
      "22  23  1.0\n",
      "23  24  1.0\n",
      "24  25  1.0\n",
      "25  26  1.0\n",
      "26  27  1.0\n",
      "27  28  1.0\n",
      "28  29  1.0\n",
      "29  30  1.0\n",
      "30  31  1.0\n",
      "31  32  1.0\n",
      "32  33  1.0\n",
      "33  34  1.0\n",
      "34  35  1.0\n",
      "35  36  1.0\n",
      "36  37  1.0\n",
      "    0    1\n",
      "0   1  1.0\n",
      "1   2  1.0\n",
      "2   3  1.0\n",
      "3   4  1.0\n",
      "4   5  1.0\n",
      "5   6  1.0\n",
      "6   7  1.0\n",
      "7   8  1.0\n",
      "8   9  1.0\n",
      "9  10  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "     0    1\n",
      "0    1  1.0\n",
      "1    2  1.0\n",
      "2    3  1.0\n",
      "3    4  1.0\n",
      "4    5  1.0\n",
      "5    6  1.0\n",
      "6    7  1.0\n",
      "7    8  1.0\n",
      "8    9  1.0\n",
      "9   10  1.0\n",
      "10  11  1.0\n",
      "11  12  1.0\n",
      "12  13  1.0\n",
      "13  14  1.0\n",
      "14  15  1.0\n",
      "15  16  1.0\n",
      "16  17  1.0\n",
      "Empty DataFrame\n",
      "Columns: [0, 1]\n",
      "Index: []\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "4  5  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "4  5  1.0\n",
      "5  6  1.0\n",
      "6  7  1.0\n",
      "     0    1\n",
      "0    1  1.0\n",
      "1    2  1.0\n",
      "2    3  1.0\n",
      "3    4  1.0\n",
      "4    5  1.0\n",
      "5    6  1.0\n",
      "6    7  1.0\n",
      "7    8  1.0\n",
      "8    9  1.0\n",
      "9   10  1.0\n",
      "10  11  1.0\n",
      "11  12  1.0\n",
      "12  13  1.0\n",
      "13  14  1.0\n",
      "14  15  1.0\n",
      "15  16  1.0\n",
      "16  17  1.0\n",
      "17  18  1.0\n",
      "18  19  1.0\n",
      "19  20  1.0\n",
      "20  21  1.0\n",
      "21  22  1.0\n",
      "22  23  1.0\n",
      "     0    1\n",
      "0    1  1.0\n",
      "1    2  1.0\n",
      "2    3  1.0\n",
      "3    4  1.0\n",
      "4    5  1.0\n",
      "5    6  1.0\n",
      "6    7  1.0\n",
      "7    8  1.0\n",
      "8    9  1.0\n",
      "9   10  1.0\n",
      "10  11  1.0\n",
      "11  12  1.0\n",
      "12  13  1.0\n",
      "13  14  1.0\n",
      "14  15  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "4  5  1.0\n",
      "5  6  1.0\n",
      "6  7  1.0\n",
      "7  8  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#f = open('LoadDataCamp.sql','w+')\n",
    "\n",
    "tablesNM = pd.read_csv(\"NMtablesCamp.csv\")\n",
    "tablesNM = np.array(tablesNM)\n",
    "tables = np.array([])\n",
    "originTables = np.array([])\n",
    "for column in tablesNM:\n",
    "    for elem in column:\n",
    "        x = getTableName(elem)\n",
    "        if(is_non_zero_file(getPath(finalpath,x+\".csv\"))):\n",
    "            tablePK = pd.DataFrame(get_tablePK(x,elem))\n",
    "            communityPK = get_communityPK(elem)\n",
    "            arrayCommunity = np.array([])\n",
    "            for index, row in tablePK.iterrows():\n",
    "                arrayCommunity = np.append(arrayCommunity,communityPK[0][0])\n",
    "            nmTableFK = concatDF(tablePK,pd.DataFrame(arrayCommunity))\n",
    "            print(nmTableFK)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
