{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb 10 17:34:18 2020\n",
    "\n",
    "@author: Guillermo Sánchez Gutiérrez-Cabello\n",
    "\"\"\"\n",
    "#%%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "#pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"popular\") # required to download the stopwords lists\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "english_stopwords = stopwords.words('english')\n",
    "#%%\n",
    "mainpath = \"C:/Users/guill/Documents/Universidad/PlataformaRefugiados/NAUTIA/DesarrolloPy/DataSetOriginales\"\n",
    "\n",
    "def fixBibliography(df):\n",
    "    df = dfFix(df,\"GENERAL INFORMATION - COUNTRY LEVEL\")\n",
    "    df.columns = ['GeneralInfo', 'CommunityCountry', 'RefugeeCountry']\n",
    "    df.set_index('GeneralInfo', inplace = True)\n",
    "    df = df.transpose()\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def dfFix(df,col1 = False,col2 = False):\n",
    "    result = df.copy()\n",
    "    if(col1):\n",
    "        x = result.columns.get_loc(col1)\n",
    "        result.drop(result.columns[0:x],axis = 1, inplace = True)\n",
    "    if(col2):\n",
    "        y = result.columns.get_loc(col2)\n",
    "        result.drop(result.columns[y:],axis = 1, inplace = True)\n",
    "    return result\n",
    "\n",
    "def validColumn(cad):\n",
    "    result = False\n",
    "    if(cad == \"index\"):#Population\n",
    "        result = True\n",
    "    else:\n",
    "        if(cad == \"Type_of_settlement\"):\n",
    "            result = True\n",
    "        else:\n",
    "            if(cad == \"General:settlement\"):\n",
    "                result = True\n",
    "            else:\n",
    "                if(cad == \"general_info:_1_1_Choose_the_settlement\"):\n",
    "                    result = True\n",
    "                else:\n",
    "                    if(cad == \"General_Information:Type_of_setlement\"):\n",
    "                        result = True\n",
    "                    else:\n",
    "                        if(cad == \"General:Settlement\"):\n",
    "                            result = True\n",
    "                        else:\n",
    "                            if(cad == \"Type_of_setlement\"):\n",
    "                                result = True\n",
    "    return result\n",
    "\n",
    "def dropRow(df,i):\n",
    "    return df.drop(index = i)\n",
    "\n",
    "def get_communityRows(df,cad,communityType): #la función pd.loc[] tiene un bug indiscriminado (https://github.com/pandas-dev/pandas/issues/8555)\n",
    "    result = df\n",
    "    if(communityType == 0):\n",
    "        comm = \"host_community\"\n",
    "    else:\n",
    "        comm = \"refugee_camp\"\n",
    "    for index, row in df.iterrows():\n",
    "        if(row[cad] != comm):\n",
    "            result = dropRow(result,index)\n",
    "    return result\n",
    "\n",
    "def setDataByIndex(df,communityType):\n",
    "    array = df.columns\n",
    "    i = 0\n",
    "    df = df.replace(\"refugee\",\"refugee_camp\")\n",
    "    df = df.replace(\"host_comunity\",\"host_community\")\n",
    "    df = df.replace(\"RefugeeCountry\",\"refugee_camp\")\n",
    "    df = df.replace(\"CommunityCountry\",\"host_community\")\n",
    "    while(validColumn(array[i]) == False):\n",
    "        i += 1\n",
    "    df = get_communityRows(df,array[i],communityType)\n",
    "    return df\n",
    "\n",
    "def set_AllCSVtoDF(communityType):\n",
    "    Bibliography = pd.read_excel(getPath(mainpath,\"Bibliography_120220.xlsx\"))\n",
    "    Bibliography = fixBibliography(Bibliography)\n",
    "    Bibliography = setDataByIndex(Bibliography,communityType)\n",
    "    Entities = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Entities_Interview_results.csv\")),communityType)\n",
    "    LocalLeaders = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Local_leaders_v3_results.csv\")),communityType)\n",
    "    HouseHold = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Survey_household_v6_results.csv\")),communityType)\n",
    "    WomenGroup = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Women_Focus_Group2_results.csv\")),communityType)\n",
    "    SanitationInfra = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_V1_0_Sanitation_Infrastructre_results.csv\")),communityType)\n",
    "    Priorities = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Priorities_v3_results.csv\")),communityType)\n",
    "    GeneralForm = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_General_form_v3_results.csv\")),communityType)\n",
    "    PublicSpace = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Public_Space_results.csv\")),communityType)\n",
    "    WaterInf = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Water_Infrastructure_results.csv\")),communityType)\n",
    "    SanitationInf = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_V1_0_Sanitation_Infrastructre_results.csv\")),communityType)\n",
    "    WasteManagementInf = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Waste_Management_Infrastructure_results.csv\")),communityType)\n",
    "    EnergyINF = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Energy_Infrastructure_results.csv\")),communityType)\n",
    "    Business = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA1_0_Business_surveys_v3_results.csv\")),communityType)\n",
    "    MobilityINF = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0__Transport_servicesaccess_points_results.csv\")),communityType) \n",
    "    ComunalServices = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Communal_Services_results.csv\")),communityType) \n",
    "    GeneralCitizen = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_General_Citizen_Focus_Group_results.csv\")),communityType)\n",
    "    Shelter = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Shelter_results.csv\")),communityType)\n",
    "    FarmyardCrop = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Farmyard_and_Crops_results.csv\")),communityType)\n",
    "    return Bibliography,Entities,LocalLeaders,HouseHold,WomenGroup,SanitationInfra,Priorities,GeneralForm,PublicSpace,WaterInf,EnergyINF,SanitationInf,WasteManagementInf,EnergyINF,Business,MobilityINF,ComunalServices,GeneralCitizen,Shelter,FarmyardCrop\n",
    "\n",
    "def concatDF(df1,df2):\n",
    "    return  pd.concat([df1,df2],axis = 1, ignore_index = True, sort = True)\n",
    "\n",
    "def mkCSV(df,fileName):\n",
    "    df = df.dropna(how = 'all')\n",
    "    df *= 1   \n",
    "    fileName = fileName.lower()\n",
    "    df.to_csv('DataSetFinales/'+fileName,sep=',',header = False, index=False, encoding='utf-8')\n",
    "    \n",
    "def getPath(mainpath,filename):\n",
    "    return os.path.join(mainpath, filename)\n",
    "\n",
    "def getSubColumnNames(df,x):\n",
    "    columns = df.columns\n",
    "    array = []\n",
    "    for column in columns:\n",
    "        column = column[x:]\n",
    "        array.append(column)\n",
    "    return pd.DataFrame(array) \n",
    "\n",
    "def addInstitutionAndType(df,array1,array2,instType):\n",
    "    df = df.dropna(axis = 1)\n",
    "    df = np.array(df)\n",
    "    for row in df:\n",
    "        for elem in row:\n",
    "            array1 = np.append(array1,elem)\n",
    "            array2 = np.append(array2,instType)\n",
    "    return array1,array2\n",
    "\n",
    "def politicalActor(df1,df2,df3,df4,df5):\n",
    "    institution = []\n",
    "    instType = []\n",
    "\n",
    "    institution, instType  = addInstitutionAndType(df1,institution,instType,'Public Institution')\n",
    "    institution, instType  = addInstitutionAndType(df2,institution,instType,'Private Institution')\n",
    "    institution, instType  = addInstitutionAndType(df3,institution,instType,'NGO')\n",
    "    institution, instType  = addInstitutionAndType(df4,institution,instType,'International Agency')\n",
    "    institution, instType  = addInstitutionAndType(df5,institution,instType,'Local')\n",
    "\n",
    "    institution = pd.DataFrame(institution)\n",
    "    institution = institution.reset_index(drop = True)\n",
    "    instType = pd.DataFrame(instType)\n",
    "    instType = instType.reset_index(drop = True)\n",
    "    \n",
    "    return concatDF(institution,instType)\n",
    "\n",
    "\n",
    "def get_claveValor(df1,df2):\n",
    "    array1 = np.array(df2)\n",
    "    array2 = np.array(df1)\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    i = 0\n",
    "    for row in array1:\n",
    "        var = array2[i]\n",
    "        for elem in row:\n",
    "            result1 = np.append(result1,elem)\n",
    "            result2 = np.append(result2,var)\n",
    "        i+=1\n",
    "    result2 = pd.DataFrame(result2)\n",
    "    result2 = result2.reset_index(drop = True)\n",
    "    result1 = pd.DataFrame(result1)\n",
    "    result1 = result1.reset_index(drop = True)\n",
    "    return concatDF(result2,result1)\n",
    "\n",
    "def get_number(df):\n",
    "    df = np.array(df)\n",
    "    array = np.array([])\n",
    "    for column in df:\n",
    "        for elem in column:\n",
    "            array = np.append(array,elem)\n",
    "    return (pd.DataFrame(array)).fillna(0) \n",
    "\n",
    "def get_valueBySector(df1,df2):\n",
    "    df2 = df2.reset_index()\n",
    "    array1 = np.array(df1)\n",
    "    i = 0\n",
    "    for row in array1:\n",
    "        for elem in row:\n",
    "            if(elem == False):\n",
    "                df2 = dropRow(df2,i)\n",
    "        i += 1\n",
    "    df2 = df2.set_index('index')\n",
    "    return df2\n",
    "\n",
    "\n",
    "def separateValues(df):\n",
    "    if(df.isnull().values.all(axis=0)):\n",
    "        result = df\n",
    "    else:\n",
    "        array = np.array(df)\n",
    "        count_vectorizer = CountVectorizer(stop_words = spanish_stopwords+english_stopwords)\n",
    "        corpus = []\n",
    "        for row in array:\n",
    "            for elem in row:\n",
    "                corpus = np.append(corpus,[elem])\n",
    "        X = count_vectorizer.fit_transform(corpus)\n",
    "        array = count_vectorizer.get_feature_names()\n",
    "        result = pd.DataFrame(array)\n",
    "    return result\n",
    "\n",
    "def vectorizeValue(df):\n",
    "    df = separateValues(df)\n",
    "    year = np.array(['january','february','march','april','may','june','july','august','september','october','november','december'])\n",
    "    result = np.array([],dtype = bool)\n",
    "    df = np.array(df)\n",
    "    for elem in year:\n",
    "        flag = False\n",
    "        for column in df:\n",
    "            for month in column:\n",
    "                if(column == elem):\n",
    "                    flag = True\n",
    "        if(flag):\n",
    "            result = np.append(result,True)\n",
    "        else:\n",
    "            result = np.append(result,False)\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "def set_sector(df,sect, concat = True):\n",
    "    sector = np.array([])\n",
    "    df = df.dropna(how = 'all')\n",
    "    df = np.array(df)\n",
    "    for column in df:\n",
    "        sector = np.append(sector,sect)\n",
    "    sector = pd.DataFrame(sector)\n",
    "    df = pd.DataFrame(df)\n",
    "    if(concat):\n",
    "        result = concatDF(sector,df)\n",
    "    else:\n",
    "        result = sector\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bibliography,Entities,LocalLeaders,HouseHold,WomenGroup,SanitationInfra,Priorities,GeneralForm,PublicSpace,WaterInf,EnergyINF,SanitationInf,WasteManagementInf,EnergyINF,Business,MobilityINF,ComunalServices,GeneralCitizen,Shelter,FarmyardCrop = set_AllCSVtoDF(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 192)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bibliography.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 72)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Entities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LocalLeaders.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HouseHold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 27)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WomenGroup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SanitationInfra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 88)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Priorities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GeneralForm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PublicSpace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WaterInf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SanitationInf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WasteManagementInf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 38)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EnergyINF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 25)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Business.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MobilityINF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 63)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComunalServices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 43)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GeneralCitizen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 27)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Shelter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 18)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FarmyardCrop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PublicSpace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfFix(Bibliography,\"Tropical (Write one: Af, Aw or Am)\",\"Temperature\")\n",
    "#df1 = dropRow(df1,0)\n",
    "df1 = df1.transpose()\n",
    "df1 = df1.dropna()\n",
    "df1 = df1.transpose()\n",
    "df2 = dfFix(Bibliography,\"Max (ºC)\",\"Annual precipitation\")\n",
    "#df2 = dropRow(df2,0)\n",
    "df3 = dfFix(Bibliography,\"Max (mm)\",\"Additional information\")\n",
    "#df3 = dropRow(df3,0)\n",
    "Camp_ClimaticRegion = concatDF(df1,concatDF(df2,df3))\n",
    "mkCSV(Camp_ClimaticRegion,\"Camp_ClimaticRegion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aw</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129</td>\n",
       "      <td>13</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4    5   6    7     8\n",
       "1  Aw  25  15  20 NaN  129  13  7.3  13.6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Camp_ClimaticRegion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dactylifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phoenix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>árbol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0        coral\n",
       "1  dactylifera\n",
       "2          nan\n",
       "3      phoenix\n",
       "4        árbol"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Camp_LocalVegetation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
