{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb 10 17:34:18 2020\n",
    "\n",
    "@author: Guillermo Sánchez Gutiérrez-Cabello\n",
    "\"\"\"\n",
    "#%%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "#pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"popular\") # required to download the stopwords lists\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "english_stopwords = stopwords.words('english')\n",
    "#%%\n",
    "mainpath = \"C:/Users/guill/Documents/Universidad/PlataformaRefugiados/NAUTIA/DesarrolloPy/DataSetOriginales\"\n",
    "\n",
    "def fixBibliography(df):\n",
    "    df = dfFix(df,\"GENERAL INFORMATION - COUNTRY LEVEL\")\n",
    "    df.columns = ['GeneralInfo', 'CommunityCountry', 'RefugeeCountry']\n",
    "    df.set_index('GeneralInfo', inplace = True)\n",
    "    df = df.transpose()\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def dfFix(df,col1 = False,col2 = False):\n",
    "    result = df.copy()\n",
    "    if(col1):\n",
    "        x = result.columns.get_loc(col1)\n",
    "        result.drop(result.columns[0:x],axis = 1, inplace = True)\n",
    "    if(col2):\n",
    "        y = result.columns.get_loc(col2)\n",
    "        result.drop(result.columns[y:],axis = 1, inplace = True)\n",
    "    return result\n",
    "\n",
    "def validColumn(cad):\n",
    "    result = False\n",
    "    if(cad == \"index\"):#Population\n",
    "        result = True\n",
    "    else:\n",
    "        if(cad == \"Type_of_settlement\"):\n",
    "            result = True\n",
    "        else:\n",
    "            if(cad == \"General:settlement\"):\n",
    "                result = True\n",
    "            else:\n",
    "                if(cad == \"general_info:_1_1_Choose_the_settlement\"):\n",
    "                    result = True\n",
    "                else:\n",
    "                    if(cad == \"General_Information:Type_of_setlement\"):\n",
    "                        result = True\n",
    "                    else:\n",
    "                        if(cad == \"General:Settlement\"):\n",
    "                            result = True\n",
    "                        else:\n",
    "                            if(cad == \"Type_of_setlement\"):\n",
    "                                result = True\n",
    "    return result\n",
    "\n",
    "def dropRow(df,i):\n",
    "    return df.drop(index = i)\n",
    "\n",
    "def get_communityRows(df,cad,communityType): #la función pd.loc[] tiene un bug indiscriminado (https://github.com/pandas-dev/pandas/issues/8555)\n",
    "    result = df\n",
    "    if(communityType == 0):\n",
    "        comm = \"host_community\"\n",
    "    else:\n",
    "        comm = \"refugee_camp\"\n",
    "    for index, row in df.iterrows():\n",
    "        if(row[cad] != comm):\n",
    "            result = dropRow(result,index)\n",
    "    return result\n",
    "\n",
    "def setDataByIndex(df,communityType):\n",
    "    array = df.columns\n",
    "    i = 0\n",
    "    df = df.replace(\"refugee\",\"refugee_camp\")\n",
    "    df = df.replace(\"host_comunity\",\"host_community\")\n",
    "    df = df.replace(\"RefugeeCountry\",\"refugee_camp\")\n",
    "    df = df.replace(\"CommunityCountry\",\"host_community\")\n",
    "    while(validColumn(array[i]) == False):\n",
    "        i += 1\n",
    "    df = get_communityRows(df,array[i],communityType)\n",
    "    return df\n",
    "\n",
    "def set_AllCSVtoDF(communityType):\n",
    "    Bibliography = pd.read_excel(getPath(mainpath,\"Bibliography_120220.xlsx\"))\n",
    "    Bibliography = fixBibliography(Bibliography)\n",
    "    Bibliography = setDataByIndex(Bibliography,communityType)\n",
    "    Entities = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Entities_Interview_results.csv\")),communityType)\n",
    "    LocalLeaders = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Local_leaders_v3_results.csv\")),communityType)\n",
    "    HouseHold = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Survey_household_v6_results.csv\")),communityType)\n",
    "    WomenGroup = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Women_Focus_Group2_results.csv\")),communityType)\n",
    "    SanitationInfra = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_V1_0_Sanitation_Infrastructre_results.csv\")),communityType)\n",
    "    Priorities = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Priorities_v3_results.csv\")),communityType)\n",
    "    GeneralForm = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_General_form_v3_results.csv\")),communityType)\n",
    "    PublicSpace = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Public_Space_results.csv\")),communityType)\n",
    "    WaterInf = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Water_Infrastructure_results.csv\")),communityType)\n",
    "    SanitationInf = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_V1_0_Sanitation_Infrastructre_results.csv\")),communityType)\n",
    "    WasteManagementInf = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Waste_Management_Infrastructure_results.csv\")),communityType)\n",
    "    EnergyINF = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Energy_Infrastructure_results.csv\")),communityType)\n",
    "    Business = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA1_0_Business_surveys_v3_results.csv\")),communityType)\n",
    "    MobilityINF = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0__Transport_servicesaccess_points_results.csv\")),communityType) \n",
    "    ComunalServices = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Communal_Services_results.csv\")),communityType) \n",
    "    GeneralCitizen = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_General_Citizen_Focus_Group_results.csv\")),communityType)\n",
    "    Shelter = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Shelter_results.csv\")),communityType)\n",
    "    FarmyardCrop = setDataByIndex(pd.read_csv(getPath(mainpath,\"NAUTIA_1_0_Farmyard_and_Crops_results.csv\")),communityType)\n",
    "    return Bibliography,Entities,LocalLeaders,HouseHold,WomenGroup,SanitationInfra,Priorities,GeneralForm,PublicSpace,WaterInf,EnergyINF,SanitationInf,WasteManagementInf,EnergyINF,Business,MobilityINF,ComunalServices,GeneralCitizen,Shelter,FarmyardCrop\n",
    "\n",
    "def concatDF(df1,df2):\n",
    "    return  pd.concat([df1,df2],axis = 1, ignore_index = True, sort = True)\n",
    "\n",
    "def mkCSV(df,fileName):\n",
    "    df = df.dropna(how = 'all')\n",
    "    df *= 1   \n",
    "    fileName = fileName.lower()\n",
    "    df.to_csv('DataSetFinales/'+fileName,sep=',',header = False, index=False, encoding='utf-8')\n",
    "    \n",
    "def getPath(mainpath,filename):\n",
    "    return os.path.join(mainpath, filename)\n",
    "\n",
    "def getSubColumnNames(df,x):\n",
    "    columns = df.columns\n",
    "    array = []\n",
    "    for column in columns:\n",
    "        column = column[x:]\n",
    "        array.append(column)\n",
    "    return pd.DataFrame(array) \n",
    "\n",
    "def addInstitutionAndType(df,array1,array2,instType):\n",
    "    df = df.dropna(axis = 1)\n",
    "    df = np.array(df)\n",
    "    for row in df:\n",
    "        for elem in row:\n",
    "            array1 = np.append(array1,elem)\n",
    "            array2 = np.append(array2,instType)\n",
    "    return array1,array2\n",
    "\n",
    "def politicalActor(df1,df2,df3,df4,df5):\n",
    "    institution = []\n",
    "    instType = []\n",
    "\n",
    "    institution, instType  = addInstitutionAndType(df1,institution,instType,'Public Institution')\n",
    "    institution, instType  = addInstitutionAndType(df2,institution,instType,'Private Institution')\n",
    "    institution, instType  = addInstitutionAndType(df3,institution,instType,'NGO')\n",
    "    institution, instType  = addInstitutionAndType(df4,institution,instType,'International Agency')\n",
    "    institution, instType  = addInstitutionAndType(df5,institution,instType,'Local')\n",
    "\n",
    "    institution = pd.DataFrame(institution)\n",
    "    institution = institution.reset_index(drop = True)\n",
    "    instType = pd.DataFrame(instType)\n",
    "    instType = instType.reset_index(drop = True)\n",
    "    \n",
    "    return concatDF(institution,instType)\n",
    "\n",
    "\n",
    "def get_claveValor(df1,df2):\n",
    "    array1 = np.array(df2)\n",
    "    array2 = np.array(df1)\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    i = 0\n",
    "    for row in array1:\n",
    "        var = array2[i]\n",
    "        for elem in row:\n",
    "            result1 = np.append(result1,elem)\n",
    "            result2 = np.append(result2,var)\n",
    "        i+=1\n",
    "    result2 = pd.DataFrame(result2)\n",
    "    result2 = result2.reset_index(drop = True)\n",
    "    result1 = pd.DataFrame(result1)\n",
    "    result1 = result1.reset_index(drop = True)\n",
    "    return concatDF(result2,result1)\n",
    "\n",
    "def get_number(df):\n",
    "    df = np.array(df)\n",
    "    array = np.array([])\n",
    "    for column in df:\n",
    "        for elem in column:\n",
    "            array = np.append(array,elem)\n",
    "    return (pd.DataFrame(array)).fillna(0) \n",
    "\n",
    "def get_valueBySector(df1,df2):\n",
    "    df2 = df2.reset_index()\n",
    "    array1 = np.array(df1)\n",
    "    i = 0\n",
    "    for row in array1:\n",
    "        for elem in row:\n",
    "            if(elem == False):\n",
    "                df2 = dropRow(df2,i)\n",
    "        i += 1\n",
    "    df2 = df2.set_index('index')\n",
    "    return df2\n",
    "\n",
    "\n",
    "def separateValues(df):\n",
    "    if(df.isnull().values.all(axis=0)):\n",
    "        result = df\n",
    "    else:\n",
    "        array = np.array(df)\n",
    "        count_vectorizer = CountVectorizer(stop_words = spanish_stopwords+english_stopwords)\n",
    "        corpus = []\n",
    "        for row in array:\n",
    "            for elem in row:\n",
    "                corpus = np.append(corpus,[elem])\n",
    "        X = count_vectorizer.fit_transform(corpus)\n",
    "        array = count_vectorizer.get_feature_names()\n",
    "        result = pd.DataFrame(array)\n",
    "    return result\n",
    "\n",
    "def vectorizeValue(df):\n",
    "    season = pd.DataFrame()\n",
    "    year = ['january','february','march','april','may','june','july','august','september','october','november','december']\n",
    "    for row in np.array(df):\n",
    "        corpus = np.array([])\n",
    "        count_vectorizer = CountVectorizer(stop_words = spanish_stopwords+english_stopwords)\n",
    "        for elem in row:\n",
    "            corpus = np.append(corpus,[elem])\n",
    "        X = count_vectorizer.fit_transform(corpus)\n",
    "        array = count_vectorizer.get_feature_names()\n",
    "        season = concatDF(season,pd.DataFrame(array))\n",
    "    season = season.T\n",
    "    result = pd.DataFrame()\n",
    "    for row in np.array(season):\n",
    "        vect = np.array([],dtype = bool)\n",
    "        for elem in year:\n",
    "            flag = False\n",
    "            for month in row:\n",
    "                if(month == elem):\n",
    "                    flag = True\n",
    "            if(flag):\n",
    "                vect = np.append(vect,True)\n",
    "            else:\n",
    "                vect = np.append(vect,False)\n",
    "        result = concatDF(result, pd.DataFrame(vect))\n",
    "    return result.T\n",
    "\n",
    "\n",
    "\n",
    "def set_sector(df,sect, concat = True):\n",
    "    sector = np.array([])\n",
    "    df = df.dropna(how = 'all')\n",
    "    df = np.array(df)\n",
    "    for column in df:\n",
    "        sector = np.append(sector,sect)\n",
    "    sector = pd.DataFrame(sector)\n",
    "    df = pd.DataFrame(df)\n",
    "    if(concat):\n",
    "        result = concatDF(sector,df)\n",
    "    else:\n",
    "        result = sector\n",
    "    return result \n",
    "\n",
    "def dropNaAndResetIndex(df):\n",
    "    df = df.dropna(how = 'all')\n",
    "    df = np.array(df)\n",
    "    return pd.DataFrame(df)\n",
    "    \n",
    "\n",
    "def get_applianceDF(df):\n",
    "    df1 = dfFix(df,0,1)\n",
    "    df2 = dfFix(df,1)\n",
    "    array = np.array([])\n",
    "    appliance = np.array([])\n",
    "    for row in np.array(df1):\n",
    "        corpus = np.array([])\n",
    "        for elem in row:\n",
    "            corpus = np.append(corpus,[elem])\n",
    "        count_vectorizer = CountVectorizer(stop_words = spanish_stopwords+english_stopwords, vocabulary = ['light_bulbs','mobile_phone','radio_music_pl','tv_dvd','laptop_tablet_','fridge','electrical_sto','others'])\n",
    "        X = count_vectorizer.fit_transform(corpus)\n",
    "        array = count_vectorizer.get_feature_names()\n",
    "        for elem in array:\n",
    "            appliance = np.append(appliance,elem)\n",
    "    appliance = pd.DataFrame(appliance)\n",
    "    hours = np.array([])\n",
    "    for row in np.array(df2):\n",
    "        for elem in row:\n",
    "            hours = np.append(hours,elem)\n",
    "    hours = pd.DataFrame(hours)\n",
    "    hours = (hours.dropna())\n",
    "    return concatDF(appliance,hours)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bibliography,Entities,LocalLeaders,HouseHold,WomenGroup,SanitationInfra,Priorities,GeneralForm,PublicSpace,WaterInf,EnergyINF,SanitationInf,WasteManagementInf,EnergyINF,Business,MobilityINF,ComunalServices,GeneralCitizen,Shelter,FarmyardCrop = set_AllCSVtoDF(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 192)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bibliography.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 72)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Entities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>General:gender</th>\n",
       "      <th>General:settlement</th>\n",
       "      <th>General:Name_host_community</th>\n",
       "      <th>Settlement_security:secur_committees</th>\n",
       "      <th>Food_security:cultivation_months</th>\n",
       "      <th>Food_security:own_food_months</th>\n",
       "      <th>Food_security:kind_food</th>\n",
       "      <th>Food_security:fertilizers</th>\n",
       "      <th>Food_security:storing_food</th>\n",
       "      <th>Food_security:dry_food</th>\n",
       "      <th>Food_security:perishable_food</th>\n",
       "      <th>Food_security:Grazing_technique</th>\n",
       "      <th>Costs:basic_basket</th>\n",
       "      <th>Costs:cost_basic_basket</th>\n",
       "      <th>Costs:cost_firewood</th>\n",
       "      <th>Costs:diesel_gensest</th>\n",
       "      <th>Costs:money_electricity</th>\n",
       "      <th>Costs:cost_solarpanels</th>\n",
       "      <th>Costs:cost_solar_panel</th>\n",
       "      <th>meta:instanceID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-27 14:13:06.49</td>\n",
       "      <td>2020-03-27 14:14:42.346</td>\n",
       "      <td>male</td>\n",
       "      <td>refugee_camp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>january february march april may june july aug...</td>\n",
       "      <td>january february march april may august july j...</td>\n",
       "      <td>cereals animals fruits vegetables none</td>\n",
       "      <td>yes</td>\n",
       "      <td>without_coolin</td>\n",
       "      <td>direct_radiati solar_dryer_eq other</td>\n",
       "      <td>60.0</td>\n",
       "      <td>alterante</td>\n",
       "      <td>yes</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>50.0</td>\n",
       "      <td>uuid:ee0aef78-441a-432e-9af1-8121d523cb16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-27 14:46:52.538</td>\n",
       "      <td>2020-03-27 20:17:53.99</td>\n",
       "      <td>female</td>\n",
       "      <td>refugee_camp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>march april may january february june july aug...</td>\n",
       "      <td>january february march may april june july aug...</td>\n",
       "      <td>vegetables cereals fruits animals none</td>\n",
       "      <td>no</td>\n",
       "      <td>without_coolin</td>\n",
       "      <td>direct_radiati solar_dryer_eq other</td>\n",
       "      <td>60.0</td>\n",
       "      <td>rotational</td>\n",
       "      <td>yes</td>\n",
       "      <td>100.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>200.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uuid:51752970-93db-4d7f-b4de-2242b2cf781a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-03-27 20:19:30.57</td>\n",
       "      <td>2020-03-27 20:20:38.754</td>\n",
       "      <td>female</td>\n",
       "      <td>refugee_camp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>january march may june</td>\n",
       "      <td>january july september</td>\n",
       "      <td>animals vegetables cereals</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>direct_radiati solar_dryer_eq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotational</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uuid:c76928fb-9fdb-44ef-a7dd-760b32ada37c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     start                      end General:gender  \\\n",
       "0   2020-03-27 14:13:06.49  2020-03-27 14:14:42.346           male   \n",
       "4  2020-03-27 14:46:52.538   2020-03-27 20:17:53.99         female   \n",
       "7   2020-03-27 20:19:30.57  2020-03-27 20:20:38.754         female   \n",
       "\n",
       "  General:settlement General:Name_host_community  \\\n",
       "0       refugee_camp                         NaN   \n",
       "4       refugee_camp                         NaN   \n",
       "7       refugee_camp                         NaN   \n",
       "\n",
       "  Settlement_security:secur_committees  \\\n",
       "0                                  yes   \n",
       "4                                  yes   \n",
       "7                                  NaN   \n",
       "\n",
       "                    Food_security:cultivation_months  \\\n",
       "0  january february march april may june july aug...   \n",
       "4  march april may january february june july aug...   \n",
       "7                             january march may june   \n",
       "\n",
       "                       Food_security:own_food_months  \\\n",
       "0  january february march april may august july j...   \n",
       "4  january february march may april june july aug...   \n",
       "7                             january july september   \n",
       "\n",
       "                  Food_security:kind_food Food_security:fertilizers  \\\n",
       "0  cereals animals fruits vegetables none                       yes   \n",
       "4  vegetables cereals fruits animals none                        no   \n",
       "7              animals vegetables cereals                        no   \n",
       "\n",
       "  Food_security:storing_food               Food_security:dry_food  \\\n",
       "0             without_coolin  direct_radiati solar_dryer_eq other   \n",
       "4             without_coolin  direct_radiati solar_dryer_eq other   \n",
       "7                        NaN        direct_radiati solar_dryer_eq   \n",
       "\n",
       "   Food_security:perishable_food Food_security:Grazing_technique  \\\n",
       "0                           60.0                       alterante   \n",
       "4                           60.0                      rotational   \n",
       "7                            NaN                      rotational   \n",
       "\n",
       "  Costs:basic_basket  Costs:cost_basic_basket  Costs:cost_firewood  \\\n",
       "0                yes                    100.0                100.0   \n",
       "4                yes                    100.0                750.0   \n",
       "7                NaN                      NaN                  NaN   \n",
       "\n",
       "  Costs:diesel_gensest  Costs:money_electricity Costs:cost_solarpanels  \\\n",
       "0                  yes                     10.0                    yes   \n",
       "4                  yes                    200.0                     no   \n",
       "7                  yes                      NaN                    NaN   \n",
       "\n",
       "   Costs:cost_solar_panel                            meta:instanceID  \n",
       "0                    50.0  uuid:ee0aef78-441a-432e-9af1-8121d523cb16  \n",
       "4                     NaN  uuid:51752970-93db-4d7f-b4de-2242b2cf781a  \n",
       "7                     NaN  uuid:c76928fb-9fdb-44ef-a7dd-760b32ada37c  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LocalLeaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HouseHold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WomenGroup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SanitationInfra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 88)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Priorities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GeneralForm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PublicSpace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WaterInf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SanitationInf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WasteManagementInf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 38)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EnergyINF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 25)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Business.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MobilityINF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 63)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComunalServices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 43)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GeneralCitizen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 27)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Shelter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 18)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FarmyardCrop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 14)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PublicSpace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_defaultColumn(df):\n",
    "    default = np.array([])\n",
    "    for row in df:\n",
    "        default = np.append(default,np.nan)\n",
    "    default = pd.DataFrame(default)\n",
    "    return concatDF(df,default)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfFix(ComunalServices,\"Health_Center\",\"Health_Center_details:Capacity\")\n",
    "df1 = df1.isin([\"hospital\"])                                                  \n",
    "df2 = dfFix(ComunalServices,\"General_Information:Record_your_current_location:Latitude\",\"General_Information:Record_your_current_location:Accuracy\")\n",
    "df3 = dfFix(ComunalServices,\"Health_Center_details:Capacity\",\"Associate_infrastructure:Sanitation\")\n",
    "S_Hospital = concatDF(df2,df3)\n",
    "S_Hospital = get_valueBySector(df1,S_Hospital)\n",
    "S_Hospital = set_defaultColumn(S_Hospital)\n",
    "S_Hospital = S_Hospital.dropna(how = 'all')\n",
    "S_Hospital[3] = S_Hospital[3].apply(np.int64)\n",
    "mkCSV(S_Hospital,\"S_Hospital.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4\n",
       "28 NaN NaN NaN  30 NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_Hospital"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
