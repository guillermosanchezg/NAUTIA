{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 21 12:34:54 2020\n",
    "\n",
    "@author: guill\n",
    "\"\"\"\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  port = 3309,\n",
    "  host=\"127.0.0.1\",\n",
    "  user=\"root\",\n",
    "  passwd=\"\",\n",
    "  database = 'nautiatoolkit'\n",
    ")\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "finalpath = \"C:/Users/guill/Documents/Universidad/PlataformaRefugiados/NAUTIA/DesarrolloPy/DataSetFinales\"\n",
    "\n",
    "def getPath(mainpath,filename):\n",
    "    return os.path.join(mainpath, filename)\n",
    "\n",
    "def mkCSV(df,fileName):\n",
    "    df = df.dropna(how = 'all')\n",
    "    df *= 1   \n",
    "    fileName = fileName.lower()\n",
    "    df.to_csv('DataSetFinales/'+fileName,sep=',',header = False, index=False, encoding='utf-8')\n",
    "    \n",
    "def concatDF(df1,df2):\n",
    "    return  pd.concat([df1,df2],axis = 1, ignore_index = True, sort = True)\n",
    "\n",
    "def mkCSV(df,fileName):\n",
    "    df = df.dropna(how = 'all')\n",
    "    df *= 1   \n",
    "    fileName = fileName.lower()\n",
    "    df.to_csv('DataSetFinales/'+fileName,sep=',',header = False, index=False, encoding='utf-8')\n",
    "\n",
    "def is_non_zero_file(fpath):\n",
    "    return os.path.isfile(fpath) and os.path.getsize(fpath)\n",
    "\n",
    "def getTableName(elem):\n",
    "    if(elem.find(\"_has_camp\") != -1):\n",
    "        x = elem.replace(\"_has_camp\",\"\")\n",
    "    else:\n",
    "        if(elem.find(\"_has_country\") != -1):\n",
    "            x = elem.replace(\"_has_country\",\"\")\n",
    "        else:\n",
    "            if(elem.find(\"_has_community\") != -1):\n",
    "                x = elem.replace(\"_has_community\",\"\")\n",
    "    return x\n",
    "def serviceTable(cad):\n",
    "    result = False\n",
    "    if(cad == \"s_educationalcenter\"):\n",
    "        result = True\n",
    "    else:\n",
    "        if(cad == \"s_primaryattention\"):\n",
    "            result = True\n",
    "        else:\n",
    "            if(cad == \"s_hospital\"):\n",
    "                result = True\n",
    "            else:\n",
    "                if(cad == \"s_othercenter\"):\n",
    "                    result = True\n",
    "    return result\n",
    "\n",
    "def isEducationalCenter(cad):\n",
    "    result = False\n",
    "    if(cad == \"s_educationalcenter\"):\n",
    "        result = True           \n",
    "    return result\n",
    "\n",
    "def isOtherCenter(cad):\n",
    "    result = False\n",
    "    if(cad == \"s_othercenter\"):\n",
    "        result = True           \n",
    "    return result\n",
    "\n",
    "def get_communityPK(elem):\n",
    "    if(elem.find(\"_has_camp\") != -1):\n",
    "        cursor.execute(\"SELECT idCamp FROM camp ORDER BY idCamp DESC LIMIT 1\")\n",
    "    else:\n",
    "        if(elem.find(\"_has_country\") != -1):\n",
    "            cursor.execute(\"SELECT idCountry FROM Country ORDER BY idCountry DESC LIMIT 1\")\n",
    "        else:\n",
    "            if(elem.find(\"_has_community\") != -1):\n",
    "                cursor.execute(\"SELECT idCommunity FROM community ORDER BY idCommunity DESC LIMIT 1\")\n",
    "    return cursor.fetchall()\n",
    "\n",
    "def get_tableFK(table):\n",
    "    cursor.execute(\"SELECT id\"+table+\" FROM \"+table+\" ORDER BY id\"+table+\" DESC LIMIT 1\")\n",
    "    return cursor.fetchall()\n",
    "\n",
    "def replacestr(df,cad1,cad2):\n",
    "    cols=list(df.columns)\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(str).str.replace(cad1,cad2)\n",
    "    return df\n",
    "\n",
    "def uniFormatTable(df):\n",
    "    df = replacestr(df,\"\\r\",\"\")\n",
    "    df = replacestr(df,\"NaN\",\"nan\")\n",
    "    df = replacestr(df,\"None\",\"nan\")\n",
    "    return df\n",
    "\n",
    "def uniFormatDF(df):\n",
    "    df = replacestr(df,\"NaN\",\"nan\")\n",
    "    df = replacestr(df,\"None\",\"nan\")\n",
    "    return df\n",
    "\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specialTableFKs(table,tableHas,x,y):\n",
    "    cursor.execute(\"SELECT * FROM \"+table)\n",
    "    df1 = uniFormatTable(pd.DataFrame(cursor.fetchall()))\n",
    "    df2 = pd.read_csv(getPath(finalpath,tableHas+\".csv\"),header = None, float_precision = \"high\")\n",
    "    df2 = uniFormatDF(df2)\n",
    "    df1 = np.array(df1)\n",
    "    pk = np.array([])\n",
    "    arrayCommunity = np.array([])\n",
    "    communityPK = get_communityPK(elem)\n",
    "    for index, row in df2.iterrows():\n",
    "        for row2 in df1:\n",
    "            if(row[x] == row2[1]):\n",
    "                pk = np.append(pk,row2[0])\n",
    "    pk = pd.DataFrame(pk)\n",
    "    for index, row in pk.iterrows():\n",
    "        arrayCommunity = np.append(arrayCommunity,communityPK[0][0])\n",
    "    arrayCommunity = pd.DataFrame(arrayCommunity)\n",
    "    result = concatDF(pk,concatDF(arrayCommunity,df2))\n",
    "    result = result.drop(result.columns[[y]], axis = 1)\n",
    "    return result\n",
    "\n",
    "def get_AreaFKs(table,tableHas,x,y):\n",
    "    cursor.execute(\"SELECT * FROM \"+table)\n",
    "    df1 = uniFormatTable(pd.DataFrame(cursor.fetchall()))\n",
    "    df2 = pd.read_csv(getPath(finalpath,tableHas+\".csv\"),header = None, float_precision = \"high\")\n",
    "    df2 = uniFormatDF(df2)\n",
    "    df1 = np.array(df1)\n",
    "    pk = np.array([])\n",
    "    area = np.array()\n",
    "    arrayCommunity = np.array([])\n",
    "    communityPK = get_communityPK(elem)\n",
    "    for index, row in df2.iterrows():\n",
    "        for row2 in df1:\n",
    "            for elem in row:\n",
    "                if(elem == row2[1]):\n",
    "                    pk = np.append(pk,row2[0])\n",
    "        for row3 in pk:\n",
    "            for elem2 in row:\n",
    "                area = np.append(area,elem2)\n",
    "    pk = pd.DataFrame(pk)\n",
    "    for index, row in pk.iterrows():\n",
    "        arrayCommunity = np.append(arrayCommunity,communityPK[0][0])\n",
    "    arrayCommunity = pd.DataFrame(arrayCommunity)\n",
    "    result = concatDF(pk,concatDF(arrayCommunity,df2))\n",
    "    result = result.drop(result.columns[[y]], axis = 1)\n",
    "    return result \n",
    "    \n",
    "def get_specialTable(table,tableHas):\n",
    "    communityPK = get_communityPK(elem)\n",
    "    result = pd.DataFrame()\n",
    "    if(tableHas == 'se_expensetype_has_community'):\n",
    "        result = get_specialTableFKs(table,tableHas,2,4)\n",
    "    else:\n",
    "        if(tableHas == 'se_worktype_has_community'):\n",
    "            result = get_specialTableFKs(table,tableHas,3,5)\n",
    "    return result\n",
    "\n",
    "\n",
    "def specialTable(cad):\n",
    "    result = False\n",
    "    if(cad == \"camp_naturalhazard_has_camp\"):\n",
    "        result = True\n",
    "    else:\n",
    "        if(cad == \"inf_appliance_has_community\"):\n",
    "            result = True\n",
    "        else:\n",
    "            if(cad == \"inf_generationsource_has_community\"):\n",
    "                result = True\n",
    "            else:\n",
    "                if(cad == \"se_expensetype_has_community\"):\n",
    "                    result = True\n",
    "                else:\n",
    "                    if(cad == \"fs_foodsource_has_community\"):\n",
    "                        result = True\n",
    "                    else:\n",
    "                        if(cad == \"fs_importantmeal_has_community\"):\n",
    "                            result = True\n",
    "                        else:\n",
    "                            if(cad == \"fs_timesperday_has_community\"):\n",
    "                                result = True\n",
    "                            else:\n",
    "                                if(cad == \"fs_typicalplate_has_community\"):\n",
    "                                    result = True\n",
    "                                else:\n",
    "                                    if(cad == \"inf_mobilityway_has_community\"):\n",
    "                                        result = True\n",
    "                                    else:\n",
    "                                        if(cad == \"s_app_has_community\"):\n",
    "                                            result = True\n",
    "                                        else:\n",
    "                                            if(cad == \"se_priority_has_community\"):\n",
    "                                                result = True\n",
    "                                            else:\n",
    "                                                if(cad == \"se_safetyplace_has_community\"):\n",
    "                                                    result = True\n",
    "                                                else:\n",
    "                                                    if(cad == \"se_worktype_has_community\"):\n",
    "                                                        result = True\n",
    "                                                    else:\n",
    "                                                        if(cad == \"u_area_has_community\"):\n",
    "                                                            result = True\n",
    "    return result\n",
    "\n",
    "def get_tablePK(table):\n",
    "    cursor.execute(\"SELECT * FROM \"+table)\n",
    "    df1 = uniFormatTable(pd.DataFrame(cursor.fetchall()))\n",
    "    df2 = pd.read_csv(getPath(finalpath,table+\".csv\"),header = None, float_precision = \"high\")\n",
    "    df2 = uniFormatDF(df2)\n",
    "    df1 = np.array(df1)\n",
    "    pk = np.array([])\n",
    "    for index, row in df2.iterrows():\n",
    "        if(serviceTable(table) == False):\n",
    "            for row2 in df1:\n",
    "                if((np.equal(np.array(row),np.array(row2[1:]))).all()):\n",
    "                    pk = np.append(pk,row2[0])\n",
    "        else:\n",
    "            if(isEducationalCenter(table)):\n",
    "                for row2 in df1:\n",
    "                    if((np.equal(np.array(row[:-2]),row2[1:-3])).all()):\n",
    "                        pk = np.append(pk,row2[0])\n",
    "            else:\n",
    "                if(isOtherCenter(table) == False):\n",
    "                    for row2 in df1:\n",
    "                        if((np.equal(np.array(row[:-1]),row2[1:-2])).all()):\n",
    "                            pk = np.append(pk,row2[0])\n",
    "                else:\n",
    "                    for row2 in df1:\n",
    "                        if((np.equal(np.array(row[:-1]),row2[1:-1])).all()):\n",
    "                            pk = np.append(pk,row2[0])\n",
    "    return pd.DataFrame(pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camp_integration_has_camp\n",
      "   0    1\n",
      "0  1  2.0\n",
      "1  2  2.0\n",
      "2  1  2.0\n",
      "3  2  2.0\n",
      "--------\n",
      "camp_localcrop_has_camp\n",
      "   0    1\n",
      "0  1  2.0\n",
      "1  2  2.0\n",
      "2  3  2.0\n",
      "--------\n",
      "camp_localvegetation_has_camp\n",
      "   0    1\n",
      "0  1  2.0\n",
      "1  2  2.0\n",
      "2  3  2.0\n",
      "3  4  2.0\n",
      "4  5  2.0\n",
      "--------\n",
      "camp_movementreason_has_camp\n",
      "   0    1\n",
      "0  1  2.0\n",
      "1  2  2.0\n",
      "2  3  2.0\n",
      "--------\n",
      "camp_naturalhazard_has_camp\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------\n",
      "country_has_camp\n",
      "   0    1\n",
      "0  1  2.0\n",
      "--------\n",
      "fs_corralubication_has_community\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "--------\n",
      "fs_cropubication_has_community\n",
      "    0    1\n",
      "0   1  1.0\n",
      "1   2  1.0\n",
      "2   3  1.0\n",
      "3   4  1.0\n",
      "4   5  1.0\n",
      "5   6  1.0\n",
      "6   7  1.0\n",
      "7   8  1.0\n",
      "8   9  1.0\n",
      "9  10  1.0\n",
      "--------\n",
      "fs_foodaccess_has_community\n",
      "   0    1    2\n",
      "0  1  1.0  6.0\n",
      "1  2  1.0  8.0\n",
      "2  3  1.0  5.0\n",
      "3  4  1.0  NaN\n",
      "--------\n",
      "fs_foodsource_has_community\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------\n",
      "fs_importantmeal_has_community\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------\n",
      "fs_owncultivationfoodtype_has_community\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "4  5  1.0\n",
      "--------\n",
      "fs_timesperday_has_community\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------\n",
      "fs_typicalplate_has_community\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------\n",
      "g_politicalactor_has_community\n",
      "     0    1\n",
      "0    3  1.0\n",
      "1    5  1.0\n",
      "2    6  1.0\n",
      "3    7  1.0\n",
      "4    8  1.0\n",
      "5    9  1.0\n",
      "6   10  1.0\n",
      "7   11  1.0\n",
      "8   12  1.0\n",
      "9   13  1.0\n",
      "10  14  1.0\n",
      "11  15  1.0\n",
      "12  17  1.0\n",
      "13  19  1.0\n",
      "--------\n",
      "gd_ethnicgroup_has_country\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "--------\n",
      "gd_language_has_country\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "--------\n",
      "gd_religion_has_country\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "4  5  1.0\n",
      "--------\n",
      "inf_appliance_has_community\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------\n",
      "inf_generationsource_has_community\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------\n",
      "inf_mobilityway_has_community\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------\n",
      "inf_sanitationsystemquality_has_community\n",
      "      0    1\n",
      "0     1  1.0\n",
      "1    11  1.0\n",
      "2    25  1.0\n",
      "3     2  1.0\n",
      "4     4  1.0\n",
      "5     5  1.0\n",
      "6     7  1.0\n",
      "7     9  1.0\n",
      "8    10  1.0\n",
      "9    12  1.0\n",
      "10   14  1.0\n",
      "11   15  1.0\n",
      "12   16  1.0\n",
      "13   20  1.0\n",
      "14   21  1.0\n",
      "15   22  1.0\n",
      "16   23  1.0\n",
      "17   24  1.0\n",
      "18   26  1.0\n",
      "19   27  1.0\n",
      "20   29  1.0\n",
      "21   32  1.0\n",
      "22    3  1.0\n",
      "23   17  1.0\n",
      "24   18  1.0\n",
      "25   19  1.0\n",
      "26   28  1.0\n",
      "27   31  1.0\n",
      "28    2  1.0\n",
      "29    4  1.0\n",
      "..   ..  ...\n",
      "407  15  1.0\n",
      "408  16  1.0\n",
      "409  20  1.0\n",
      "410  21  1.0\n",
      "411  22  1.0\n",
      "412  23  1.0\n",
      "413  24  1.0\n",
      "414  26  1.0\n",
      "415  27  1.0\n",
      "416  29  1.0\n",
      "417  32  1.0\n",
      "418  33  1.0\n",
      "419  35  1.0\n",
      "420   8  1.0\n",
      "421  30  1.0\n",
      "422  34  1.0\n",
      "423  36  1.0\n",
      "424  37  1.0\n",
      "425  33  1.0\n",
      "426  35  1.0\n",
      "427   8  1.0\n",
      "428  30  1.0\n",
      "429  34  1.0\n",
      "430  36  1.0\n",
      "431  37  1.0\n",
      "432   8  1.0\n",
      "433  30  1.0\n",
      "434  34  1.0\n",
      "435  36  1.0\n",
      "436  37  1.0\n",
      "\n",
      "[437 rows x 2 columns]\n",
      "--------\n",
      "s_app_has_community\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------\n",
      "s_cementery_has_community\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "--------\n",
      "s_dataaccess_has_community\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "--------\n",
      "s_educationalcenter_has_community\n",
      "     0    1\n",
      "0    1  1.0\n",
      "1    2  1.0\n",
      "2    3  1.0\n",
      "3    4  1.0\n",
      "4    5  1.0\n",
      "5    6  1.0\n",
      "6    7  1.0\n",
      "7    8  1.0\n",
      "8    9  1.0\n",
      "9   10  1.0\n",
      "10  11  1.0\n",
      "11  12  1.0\n",
      "12  13  1.0\n",
      "13  14  1.0\n",
      "14  15  1.0\n",
      "15  16  1.0\n",
      "16  17  1.0\n",
      "--------\n",
      "s_hospital_has_community\n",
      "   0    1\n",
      "0  1  1.0\n",
      "--------\n",
      "s_noeducationcause_has_community\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "4  5  1.0\n",
      "--------\n",
      "s_othercenter_has_community\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "3  4  1.0\n",
      "--------\n",
      "s_primaryattention_has_community\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  3  1.0\n",
      "--------\n",
      "s_tecknowlege_has_community\n",
      "   0    1     2\n",
      "0  1  1.0  40.0\n",
      "1  2  1.0   0.0\n",
      "2  3  1.0   0.0\n",
      "3  4  1.0   NaN\n",
      "--------\n",
      "se_cleaningmaterial_has_community\n",
      "   0    1\n",
      "0  1  1.0\n",
      "1  2  1.0\n",
      "2  1  1.0\n",
      "3  2  1.0\n",
      "4  3  1.0\n",
      "--------\n",
      "se_conflictarea_has_community\n",
      "   0    1\n",
      "0  1  1.0\n",
      "--------\n",
      "se_expensetype_has_community\n",
      "     0    1       2       3\n",
      "0    1  1.0  female     nan\n",
      "1    2  1.0  female  3000.0\n",
      "2    3  1.0  female     0.0\n",
      "3    4  1.0  female     0.0\n",
      "4    5  1.0  female  5000.0\n",
      "5    6  1.0  female     0.0\n",
      "6    7  1.0  female     0.0\n",
      "7    1  1.0  female  5000.0\n",
      "8    2  1.0  female   500.0\n",
      "9    3  1.0  female     0.0\n",
      "10   4  1.0  female     0.0\n",
      "11   5  1.0  female   500.0\n",
      "12   6  1.0  female     0.0\n",
      "13   7  1.0  female     0.0\n",
      "14   1  1.0  female   300.0\n",
      "15   2  1.0  female     nan\n",
      "16   3  1.0  female     nan\n",
      "17   4  1.0  female     nan\n",
      "18   5  1.0  female     nan\n",
      "19   6  1.0  female   100.0\n",
      "20   7  1.0  female    40.0\n",
      "21   1  1.0  female  1000.0\n",
      "22   2  1.0  female     nan\n",
      "23   3  1.0  female     nan\n",
      "24   4  1.0  female     nan\n",
      "25   5  1.0  female     nan\n",
      "26   6  1.0  female     nan\n",
      "27   7  1.0  female  1000.0\n",
      "28   1  1.0    male  1000.0\n",
      "29   2  1.0    male     nan\n",
      "..  ..  ...     ...     ...\n",
      "138  6  1.0  female     nan\n",
      "139  7  1.0  female   500.0\n",
      "140  1  1.0  female     nan\n",
      "141  2  1.0  female     nan\n",
      "142  3  1.0  female     nan\n",
      "143  4  1.0  female     nan\n",
      "144  5  1.0  female     nan\n",
      "145  6  1.0  female     nan\n",
      "146  7  1.0  female   500.0\n",
      "147  1  1.0  female   100.0\n",
      "148  2  1.0  female   100.0\n",
      "149  3  1.0  female     0.0\n",
      "150  4  1.0  female     0.0\n",
      "151  5  1.0  female     0.0\n",
      "152  6  1.0  female     nan\n",
      "153  7  1.0  female   300.0\n",
      "154  1  1.0    male     nan\n",
      "155  2  1.0    male     nan\n",
      "156  3  1.0    male     nan\n",
      "157  4  1.0    male     0.0\n",
      "158  5  1.0    male     0.0\n",
      "159  6  1.0    male     nan\n",
      "160  7  1.0    male   350.0\n",
      "161  1  1.0  female    30.0\n",
      "162  2  1.0  female    10.0\n",
      "163  3  1.0  female    20.0\n",
      "164  4  1.0  female    20.0\n",
      "165  5  1.0  female    40.0\n",
      "166  6  1.0  female    40.0\n",
      "167  7  1.0  female    40.0\n",
      "\n",
      "[168 rows x 4 columns]\n",
      "--------\n",
      "se_incometype_has_community\n",
      "      0    1\n",
      "0     1  1.0\n",
      "1     7  1.0\n",
      "2     9  1.0\n",
      "3    11  1.0\n",
      "4    13  1.0\n",
      "5    17  1.0\n",
      "6    18  1.0\n",
      "7    19  1.0\n",
      "8    20  1.0\n",
      "9     2  1.0\n",
      "10    3  1.0\n",
      "11    4  1.0\n",
      "12    6  1.0\n",
      "13    8  1.0\n",
      "14   10  1.0\n",
      "15   14  1.0\n",
      "16   15  1.0\n",
      "17   16  1.0\n",
      "18   22  1.0\n",
      "19   23  1.0\n",
      "20    5  1.0\n",
      "21   12  1.0\n",
      "22    4  1.0\n",
      "23    6  1.0\n",
      "24    8  1.0\n",
      "25   10  1.0\n",
      "26   14  1.0\n",
      "27   15  1.0\n",
      "28   16  1.0\n",
      "29   22  1.0\n",
      "..   ..  ...\n",
      "139  19  1.0\n",
      "140  20  1.0\n",
      "141   1  1.0\n",
      "142   7  1.0\n",
      "143   9  1.0\n",
      "144  11  1.0\n",
      "145  13  1.0\n",
      "146  17  1.0\n",
      "147  18  1.0\n",
      "148  19  1.0\n",
      "149  20  1.0\n",
      "150  21  1.0\n",
      "151   4  1.0\n",
      "152   6  1.0\n",
      "153   8  1.0\n",
      "154  10  1.0\n",
      "155  14  1.0\n",
      "156  15  1.0\n",
      "157  16  1.0\n",
      "158  22  1.0\n",
      "159  23  1.0\n",
      "160   4  1.0\n",
      "161   6  1.0\n",
      "162   8  1.0\n",
      "163  10  1.0\n",
      "164  14  1.0\n",
      "165  15  1.0\n",
      "166  16  1.0\n",
      "167  22  1.0\n",
      "168  23  1.0\n",
      "\n",
      "[169 rows x 2 columns]\n",
      "--------\n",
      "se_priority_has_community\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------\n",
      "se_safetyplace_has_community\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------\n",
      "se_worktype_has_community\n",
      "   0    1     2     3     4\n",
      "0  1  1.0  20.0  10.0  20.0\n",
      "1  2  1.0  15.0  10.0  25.0\n",
      "--------\n",
      "u_area_has_community\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "#f = open('LoadDataCamp.sql','w+')\n",
    "\n",
    "tablesNM = pd.read_csv(\"NMtablesCamp.csv\")\n",
    "tablesNM = np.array(tablesNM)\n",
    "tables = np.array([])\n",
    "originTables = np.array([])\n",
    "for column in tablesNM:\n",
    "    for elem in column:\n",
    "        x = getTableName(elem)\n",
    "        if(is_non_zero_file(getPath(finalpath,x+\".csv\"))):\n",
    "            if(specialTable(elem) == False):\n",
    "                tablePK = get_tablePK(x)\n",
    "                communityPK = get_communityPK(elem)\n",
    "                arrayCommunity = np.array([])\n",
    "                for index, row in tablePK.iterrows():\n",
    "                    arrayCommunity = np.append(arrayCommunity,communityPK[0][0])\n",
    "                nmTableFK = concatDF(tablePK,pd.DataFrame(arrayCommunity))\n",
    "                if(os.path.isfile(finalpath+\"/\"+elem+\".csv\")):\n",
    "                    if(is_non_zero_file(getPath(finalpath,elem+\".csv\"))):\n",
    "                        df = np.array(pd.read_csv(finalpath+\"/\"+elem+\".csv\"))\n",
    "                        df = pd.DataFrame(df)\n",
    "                        nmTableFK = concatDF(nmTableFK,df)\n",
    "            else:\n",
    "                nmTableFK = get_specialTable(x,elem)\n",
    "            print(elem)\n",
    "            print(nmTableFK)\n",
    "            print(\"--------\")\n",
    "            mkCSV(nmTableFK,elem+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
