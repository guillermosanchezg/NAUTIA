{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 21 12:34:54 2020\n",
    "\n",
    "@author: guill\n",
    "\"\"\"\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "#pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "#import nltk\n",
    "#nltk.download(\"popular\") # required to download the stopwords lists\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "#spanish_stopwords = stopwords.words('spanish')\n",
    "#english_stopwords = stopwords.words('english')\n",
    "\n",
    "originalpath = \"C:/Users/guill/Documents/Universidad/PlataformaRefugiados/NAUTIA/DesarrolloPy/DataSetOriginales\"\n",
    "finalpath = \"C:/Users/guill/Documents/Universidad/PlataformaRefugiados/NAUTIA/DesarrolloPy/DataSetFinales\"\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  port = 3309,\n",
    "  host=\"127.0.0.1\",\n",
    "  user=\"root\",\n",
    "  passwd=\"\",\n",
    "  database = 'nautiatoolkit'\n",
    ")\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "def is_non_zero_file(fpath):\n",
    "    return os.path.isfile(fpath) and os.path.getsize(fpath)\n",
    "\n",
    "def getTableName(elem):\n",
    "    if(elem.find(\"_has_camp\") != -1):\n",
    "        x = elem.replace(\"_has_camp\",\"\")\n",
    "    else:\n",
    "        if(elem.find(\"_has_country\") != -1):\n",
    "            x = elem.replace(\"_has_country\",\"\")\n",
    "        else:\n",
    "            if(elem.find(\"_has_community\") != -1):\n",
    "                x = elem.replace(\"_has_community\",\"\")\n",
    "    return x\n",
    "\n",
    "#AQUIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "\n",
    "def get_communityFK(elem):\n",
    "    if(elem.find(\"_has_camp\") != -1):\n",
    "        cursor.execute(\"SELECT idCamp FROM camp ORDER BY idCamp DESC LIMIT 1\")\n",
    "    else:\n",
    "        if(elem.find(\"_has_country\") != -1):\n",
    "            cursor.execute(\"SELECT idCountry FROM Country ORDER BY idCountry DESC LIMIT 1\")\n",
    "        else:\n",
    "            if(elem.find(\"_has_community\") != -1):\n",
    "                cursor.execute(\"SELECT idCommunity FROM community ORDER BY idCommunity DESC LIMIT 1\")\n",
    "    return cursor.fetchall()\n",
    "\n",
    "def get_tableFK(df,index):\n",
    "    array = np.array(df)\n",
    "    return array[index][0]\n",
    "\n",
    "\n",
    "def fixBibliography(df):\n",
    "    df = dfFix(df,\"GENERAL INFORMATION - COUNTRY LEVEL\")\n",
    "    df.columns = ['GeneralInfo', 'CommunityCountry', 'RefugeeCountry']\n",
    "    df.set_index('GeneralInfo', inplace = True)\n",
    "    df = df.transpose()\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def dfFix(df,col1 = False,col2 = False):\n",
    "    result = df.copy()\n",
    "    if(col1):\n",
    "        x = result.columns.get_loc(col1)\n",
    "        result.drop(result.columns[0:x],axis = 1, inplace = True)\n",
    "    if(col2):\n",
    "        y = result.columns.get_loc(col2)\n",
    "        result.drop(result.columns[y:],axis = 1, inplace = True)\n",
    "    return result\n",
    "\n",
    "def validColumn(cad):\n",
    "    result = False\n",
    "    if(cad == \"index\"):#Population\n",
    "        result = True\n",
    "    else:\n",
    "        if(cad == \"Type_of_settlement\"):\n",
    "            result = True\n",
    "        else:\n",
    "            if(cad == \"General:settlement\"):\n",
    "                result = True\n",
    "            else:\n",
    "                if(cad == \"general_info:_1_1_Choose_the_settlement\"):\n",
    "                    result = True\n",
    "                else:\n",
    "                    if(cad == \"General_Information:Type_of_setlement\"):\n",
    "                        result = True\n",
    "                    else:\n",
    "                        if(cad == \"General:Settlement\"):\n",
    "                            result = True\n",
    "                        else:\n",
    "                            if(cad == \"Type_of_setlement\"):\n",
    "                                result = True\n",
    "    return result\n",
    "\n",
    "def dropRow(df,i):\n",
    "    return df.drop(index = i)\n",
    "\n",
    "def get_communityRows(df,cad,communityType): #la función pd.loc[] tiene un bug indiscriminado (https://github.com/pandas-dev/pandas/issues/8555)\n",
    "    result = df\n",
    "    if(communityType == 0):\n",
    "        comm = \"host_community\"\n",
    "    else:\n",
    "        comm = \"refugee_camp\"\n",
    "    for index, row in df.iterrows():\n",
    "        if(row[cad] != comm):\n",
    "            result = dropRow(result,index)\n",
    "    return result\n",
    "\n",
    "def setDataByIndex(df,communityType):\n",
    "    array = df.columns\n",
    "    i = 0\n",
    "    df = df.replace(\"refugee\",\"refugee_camp\")\n",
    "    df = df.replace(\"host_comunity\",\"host_community\")\n",
    "    df = df.replace(\"RefugeeCountry\",\"refugee_camp\")\n",
    "    df = df.replace(\"CommunityCountry\",\"host_community\")\n",
    "    while(validColumn(array[i]) == False):\n",
    "        i += 1\n",
    "    df = get_communityRows(df,array[i],communityType)\n",
    "    return df\n",
    "\n",
    "def set_AllCSVtoDF(communityType):\n",
    "    Bibliography = pd.read_excel(getPath(originalpath,\"Bibliography_120220.xlsx\"))\n",
    "    Bibliography = fixBibliography(Bibliography)\n",
    "    Bibliography = setDataByIndex(Bibliography,communityType)\n",
    "    Entities = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Entities_Interview_results.csv\")),communityType)\n",
    "    LocalLeaders = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Local_leaders_v3_results.csv\")),communityType)\n",
    "    HouseHold = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Survey_household_v6_results.csv\")),communityType)\n",
    "    WomenGroup = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Women_Focus_Group2_results.csv\")),communityType)\n",
    "    SanitationInfra = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_V1_0_Sanitation_Infrastructre_results.csv\")),communityType)\n",
    "    Priorities = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Priorities_v3_results.csv\")),communityType)\n",
    "    GeneralForm = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_General_form_v3_results.csv\")),communityType)\n",
    "    PublicSpace = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Public_Space_results.csv\")),communityType)\n",
    "    WaterInf = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Water_Infrastructure_results.csv\")),communityType)\n",
    "    SanitationInf = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_V1_0_Sanitation_Infrastructre_results.csv\")),communityType)\n",
    "    WasteManagementInf = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Waste_Management_Infrastructure_results.csv\")),communityType)\n",
    "    EnergyINF = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Energy_Infrastructure_results.csv\")),communityType)\n",
    "    Business = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA1_0_Business_surveys_v3_results.csv\")),communityType)\n",
    "    MobilityINF = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0__Transport_servicesaccess_points_results.csv\")),communityType) \n",
    "    ComunalServices = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Communal_Services_results.csv\")),communityType) \n",
    "    GeneralCitizen = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_General_Citizen_Focus_Group_results.csv\")),communityType)\n",
    "    Shelter = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Shelter_results.csv\")),communityType)\n",
    "    FarmyardCrop = setDataByIndex(pd.read_csv(getPath(originalpath,\"NAUTIA_1_0_Farmyard_and_Crops_results.csv\")),communityType)\n",
    "    return Bibliography,Entities,LocalLeaders,HouseHold,WomenGroup,SanitationInfra,Priorities,GeneralForm,PublicSpace,WaterInf,EnergyINF,SanitationInf,WasteManagementInf,EnergyINF,Business,MobilityINF,ComunalServices,GeneralCitizen,Shelter,FarmyardCrop\n",
    "\n",
    "def concatDF(df1,df2):\n",
    "    return  pd.concat([df1,df2],axis = 1, ignore_index = True, sort = True)\n",
    "\n",
    "def mkCSV(df,fileName):\n",
    "    df = df.dropna(how = 'all')\n",
    "    df *= 1   \n",
    "    fileName = fileName.lower()\n",
    "    df.to_csv('DataSetFinales/'+fileName,sep=',',header = False, index=False, encoding='utf-8')\n",
    "    \n",
    "def getPath(mainpath,filename):\n",
    "    return os.path.join(mainpath, filename)\n",
    "\n",
    "def getSubColumnNames(df,x):\n",
    "    columns = df.columns\n",
    "    array = []\n",
    "    for column in columns:\n",
    "        column = column[x:]\n",
    "        array.append(column)\n",
    "    return pd.DataFrame(array) \n",
    "\n",
    "def addInstitutionAndType(df,array1,array2,instType):\n",
    "    df = df.dropna(axis = 1)\n",
    "    df = np.array(df)\n",
    "    for row in df:\n",
    "        for elem in row:\n",
    "            array1 = np.append(array1,elem)\n",
    "            array2 = np.append(array2,instType)\n",
    "    return array1,array2\n",
    "\n",
    "def politicalActor(df1,df2,df3,df4,df5):\n",
    "    institution = []\n",
    "    instType = []\n",
    "\n",
    "    institution, instType  = addInstitutionAndType(df1,institution,instType,'Public Institution')\n",
    "    institution, instType  = addInstitutionAndType(df2,institution,instType,'Private Institution')\n",
    "    institution, instType  = addInstitutionAndType(df3,institution,instType,'NGO')\n",
    "    institution, instType  = addInstitutionAndType(df4,institution,instType,'International Agency')\n",
    "    institution, instType  = addInstitutionAndType(df5,institution,instType,'Local')\n",
    "\n",
    "    institution = pd.DataFrame(institution)\n",
    "    institution = institution.reset_index(drop = True)\n",
    "    instType = pd.DataFrame(instType)\n",
    "    instType = instType.reset_index(drop = True)\n",
    "    \n",
    "    return concatDF(institution,instType)\n",
    "\n",
    "\n",
    "def get_claveValor(df1,df2):\n",
    "    array1 = np.array(df2)\n",
    "    array2 = np.array(df1)\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    i = 0\n",
    "    for row in array1:\n",
    "        var = array2[i]\n",
    "        for elem in row:\n",
    "            result1 = np.append(result1,elem)\n",
    "            result2 = np.append(result2,var)\n",
    "        i+=1\n",
    "    result2 = pd.DataFrame(result2)\n",
    "    result2 = result2.reset_index(drop = True)\n",
    "    result1 = pd.DataFrame(result1)\n",
    "    result1 = result1.reset_index(drop = True)\n",
    "    return concatDF(result2,result1)\n",
    "\n",
    "def get_number(df):\n",
    "    df = np.array(df)\n",
    "    array = np.array([])\n",
    "    for column in df:\n",
    "        for elem in column:\n",
    "            array = np.append(array,elem)\n",
    "    return (pd.DataFrame(array)).fillna(0) \n",
    "\n",
    "def get_valueBySector(df1,df2):\n",
    "    df2 = df2.reset_index()\n",
    "    array1 = np.array(df1)\n",
    "    i = 0\n",
    "    for row in array1:\n",
    "        for elem in row:\n",
    "            if(elem == False):\n",
    "                df2 = dropRow(df2,i)\n",
    "        i += 1\n",
    "    df2 = df2.set_index('index')\n",
    "    return df2\n",
    "\n",
    "\n",
    "def separateValues(df):\n",
    "    if(df.isnull().values.all(axis=0)):\n",
    "        result = df\n",
    "    else:\n",
    "        array = np.array(df)\n",
    "        count_vectorizer = CountVectorizer(stop_words = spanish_stopwords+english_stopwords)\n",
    "        corpus = []\n",
    "        for row in array:\n",
    "            for elem in row:\n",
    "                corpus = np.append(corpus,[elem])\n",
    "        X = count_vectorizer.fit_transform(corpus)\n",
    "        array = count_vectorizer.get_feature_names()\n",
    "        result = pd.DataFrame(array)\n",
    "    return result\n",
    "\n",
    "def vectorizeValue(df):\n",
    "    df = separateValues(df)\n",
    "    year = np.array(['january','february','march','april','may','june','july','august','september','october','november','december'])\n",
    "    result = np.array([],dtype = bool)\n",
    "    df = np.array(df)\n",
    "    for elem in year:\n",
    "        flag = False\n",
    "        for column in df:\n",
    "            for month in column:\n",
    "                if(column == elem):\n",
    "                    flag = True\n",
    "        if(flag):\n",
    "            result = np.append(result,True)\n",
    "        else:\n",
    "            result = np.append(result,False)\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "def set_sector(df,sect, concat = True):\n",
    "    sector = np.array([])\n",
    "    df = df.dropna(how = 'all')\n",
    "    df = np.array(df)\n",
    "    for column in df:\n",
    "        sector = np.append(sector,sect)\n",
    "    sector = pd.DataFrame(sector)\n",
    "    df = pd.DataFrame(df)\n",
    "    if(concat):\n",
    "        result = concatDF(sector,df)\n",
    "    else:\n",
    "        result = sector\n",
    "    return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replacestr(df,cad1,cad2):\n",
    "    cols=list(df.columns)\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(str).str.replace(cad1,cad2)\n",
    "    return df\n",
    "\n",
    "def selectAll(table,community):\n",
    "    cursor.execute(\"SELECT * FROM \"+table)\n",
    "    df1 = pd.DataFrame(cursor.fetchall())\n",
    "    df1 = replacestr(df1,\"\\r\",\"\")\n",
    "    df1 = replacestr(df1,\"NaN\",\"nan\")\n",
    "    df1 = replacestr(df1,\"None\",\"nan\")\n",
    "    df2 = pd.read_csv(getPath(finalpath,table+\".csv\"), float_precision = \"high\")\n",
    "    df2 = replacestr(df2,\"NaN\",\"nan\")\n",
    "    df2 = replacestr(df2,\"None\",\"nan\")\n",
    "    df1 = np.array(df1)\n",
    "    for index, row in df2.iterrows():\n",
    "        print(table)\n",
    "        print(np.array(row))\n",
    "        print(df1[index][:])\n",
    "        print(\"-----------\")\n",
    "        if(np.equal(np.array(row),df1[index][1:])):\n",
    "            print(\"LEEETS GOOO\")\n",
    "            print(np.array(row))\n",
    "            print(df1[index][1:])\n",
    "            print(\"-----------\")\n",
    "    #return cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camp_integration\n",
      "['comercial']\n",
      "['1' 'comercial']\n",
      "-----------\n",
      "LEEETS GOOO\n",
      "['comercial']\n",
      "['comercial']\n",
      "-----------\n",
      "camp_localcrop\n",
      "['one']\n",
      "['1' 'nan']\n",
      "-----------\n",
      "camp_localcrop\n",
      "['teff']\n",
      "['2' 'one']\n",
      "-----------\n",
      "camp_localvegetation\n",
      "['dactylifera']\n",
      "['1' 'coral']\n",
      "-----------\n",
      "camp_localvegetation\n",
      "['nan']\n",
      "['2' 'dactylifera']\n",
      "-----------\n",
      "camp_localvegetation\n",
      "['phoenix']\n",
      "['3' 'nan']\n",
      "-----------\n",
      "camp_localvegetation\n",
      "['árbol']\n",
      "['4' 'phoenix']\n",
      "-----------\n",
      "camp_movementreason\n",
      "['poor']\n",
      "['1' 'war']\n",
      "-----------\n",
      "camp_movementreason\n",
      "['politic persecution']\n",
      "['2' 'poor']\n",
      "-----------\n",
      "camp_naturalhazard\n",
      "['dryness']\n",
      "['1' 'Flood']\n",
      "-----------\n",
      "camp_naturalhazard\n",
      "['earthquake']\n",
      "['2' 'dryness']\n",
      "-----------\n",
      "camp_naturalhazard\n",
      "['storm']\n",
      "['3' 'earthquake']\n",
      "-----------\n",
      "camp_naturalhazard\n",
      "['plage']\n",
      "['4' 'storm']\n",
      "-----------\n",
      "fs_corralubication\n",
      "['27.4862459018' '-7.8239242989' '457.145955847' 'private__insid' '0']\n",
      "['1' '27.4977' '-7.82859' '463.287' 'public' '0']\n",
      "-----------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1a14c98e8b0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetTableName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_non_zero_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselectAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mcommunityFK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_communityFK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0marrayTable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-0276658251ee>\u001b[0m in \u001b[0;36mselectAll\u001b[1;34m(table, community)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-----------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LEEETS GOOO\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "\n",
    "#f = open('LoadDataCamp.sql','w+')\n",
    "\n",
    "tablesNM = pd.read_csv(\"NMtablesCamp.csv\")\n",
    "tablesNM = np.array(tablesNM)\n",
    "tables = np.array([])\n",
    "originTables = np.array([])\n",
    "for column in tablesNM:\n",
    "    for elem in column:\n",
    "        x = getTableName(elem)\n",
    "        if(is_non_zero_file(getPath(finalpath,x+\".csv\"))):\n",
    "            table = pd.DataFrame(selectAll(x,elem))\n",
    "            communityFK = get_communityFK(elem)\n",
    "            arrayTable = np.array([])\n",
    "            arrayCommunity = np.array([])\n",
    "            for index, row in table.iterrows():\n",
    "                tableFK = get_tableFK(table, index)\n",
    "                arrayTable = np.append(arrayTable,tableFK)\n",
    "                arrayCommunity = np.append(arrayCommunity,communityFK[0][0])\n",
    "            tableNM = concatDF((pd.DataFrame(arrayTable)),(pd.DataFrame(arrayCommunity)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
